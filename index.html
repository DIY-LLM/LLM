<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DIY LLM Toolkit | Modular Prototype</title>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.10.0/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js@3.7.1/dist/chart.min.js"></script>
    
    <style>
        /* --- Google Cloud/Material Design Variables --- */
        :root {
            --primary-blue: #1A73E8; /* Deep Google Blue */
            --header-blue: #1A2E44; /* Darker blue for a professional app bar */
            --nav-panel-color: #F1F3F4;
            --active-item-color: #E8F0FE;
            --surface-color: #FFFFFF;
            --background-color: #F8F9FA;
            --text-color: #202124;
            --secondary-text: #5F6368;
            --border-color: #DADCE0;
            --google-red: #DB4437;
            --google-green: #0F9D58;
            --elevation-low: 0 1px 2px 0 rgba(0,0,0,0.1), 0 1px 3px 0 rgba(0,0,0,0.06);
            --elevation-mid: 0 2px 4px 0 rgba(0,0,0,0.1), 0 2px 5px 0 rgba(0,0,0,0.08);
        }
        /* --- Base Layout --- */
        body {
            font-family: 'Roboto', sans-serif;
            background-color: var(--background-color);
            color: var(--text-color);
            margin: 0;
            padding: 0;
            display: flex;
            flex-direction: column;
            min-height: 100vh;
        }
        .top-header {
            background-color: var(--header-blue);
            color: var(--surface-color);
            padding: 10px 20px;
            display: flex;
            align-items: center;
            box-shadow: var(--elevation-low);
            z-index: 10;
        }
        .top-header h1 { font-size: 1.5em; font-weight: 400; margin: 0 30px 0 10px; white-space: nowrap; }
        .top-header h1 i { color: #4285F4; margin-right: 8px; }
        .main-content-area { display: flex; flex-grow: 1; }
        .side-nav {
            width: 250px;
            background-color: var(--surface-color);
            border-right: 1px solid var(--border-color);
            padding: 15px 0;
            flex-shrink: 0;
        }
        .nav-item { padding: 10px 20px; color: var(--secondary-text); font-size: 0.95em; cursor: pointer; transition: background-color 0.2s; }
        .nav-item.active { background-color: var(--active-item-color); color: var(--primary-blue); border-left: 3px solid var(--primary-blue); font-weight: 500; padding-left: 17px; }
        .nav-item i { margin-right: 12px; font-size: 1.1em; width: 20px; text-align: center; }
        .content-wrapper { flex-grow: 1; padding: 30px; max-width: 1000px; }
        h2 { color: var(--text-color); font-weight: 500; font-size: 1.6em; margin-top: 0; margin-bottom: 20px; }
        .divider { margin: 30px 0; border: none; border-top: 1px solid var(--border-color); }
        
        /* Model Mode Toggle */
        .mode-toggle {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 20px;
            padding: 10px 15px;
            background-color: var(--surface-color);
            border-radius: 8px;
            box-shadow: var(--elevation-low);
            border-left: 4px solid var(--primary-blue);
        }
        .toggle-switch { position: relative; display: inline-block; width: 60px; height: 34px; }
        .toggle-switch input { opacity: 0; width: 0; height: 0; }
        .slider { position: absolute; cursor: pointer; top: 0; left: 0; right: 0; bottom: 0; background-color: #ccc; transition: .4s; border-radius: 34px; }
        .slider:before { position: absolute; content: ""; height: 26px; width: 26px; left: 4px; bottom: 4px; background-color: white; transition: .4s; border-radius: 50%; }
        input:checked + .slider { background-color: var(--google-green); }
        input:checked + .slider:before { transform: translateX(26px); }
        .mode-label { font-weight: 500; margin-right: 15px; color: var(--primary-blue); }
        .mode-label span { color: var(--secondary-text); font-weight: 400; font-size: 0.9em;}
        
        /* Model Controls Panel (Phase 4) */
        #model-controls-panel {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 15px;
            padding: 20px;
            background-color: var(--surface-color);
            border-radius: 8px;
            box-shadow: var(--elevation-low);
            margin-bottom: 20px;
        }
        .control-group label { display: block; font-size: 0.85em; color: var(--secondary-text); margin-bottom: 5px; }
        .control-group input[type="number"], .control-group select {
            width: 100%;
            padding: 8px;
            border: 1px solid var(--border-color);
            border-radius: 4px;
            box-sizing: border-box;
            font-size: 0.9em;
            color: var(--text-color);
        }
        
        /* Dashboard (Phase 4) */
        #model-dashboard {
            display: grid;
            grid-template-columns: 2fr 1fr;
            gap: 20px;
            margin-top: 30px;
        }
        #chart-container {
            background-color: var(--surface-color);
            padding: 20px;
            border-radius: 8px;
            box-shadow: var(--elevation-low);
        }
        #metrics-panel {
            background-color: var(--surface-color);
            padding: 20px;
            border-radius: 8px;
            box-shadow: var(--elevation-low);
            border-left: 4px solid var(--google-green);
        }
        #metrics-panel h3 { margin-top: 0; color: var(--google-green); font-weight: 500; font-size: 1.2em; }
        .metric-item { margin-bottom: 10px; font-size: 0.95em; }
        .metric-item strong { display: block; font-size: 1.1em; color: var(--text-color); }
        
        /* NEW: Data Analytics Dashboard */
        #data-analytics-dashboard {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
            margin-top: 20px;
        }
        .dashboard-card {
            background-color: var(--surface-color);
            padding: 20px;
            border-radius: 8px;
            box-shadow: var(--elevation-low);
        }
        .dashboard-card h3 { 
            margin-top: 0; 
            font-size: 1.2em; 
            color: var(--primary-blue);
        }
        /* NEW: Heatmap specific styles */
        #transition-heatmap-content {
            overflow-x: auto;
            max-height: 350px;
        }
        #transition-heatmap-content table {
            width: 100%;
            border-collapse: collapse;
            font-size: 0.75em;
            table-layout: fixed;
        }
        #transition-heatmap-content th, #transition-heatmap-content td {
            border: 1px solid #eee;
            padding: 5px;
            text-align: center;
            transition: background-color 0.3s;
            overflow: hidden;
            white-space: nowrap;
            text-overflow: ellipsis;
            height: 30px;
        }
        #transition-heatmap-content th {
            background-color: #f7f7f7;
            font-weight: 500;
        }
        .heatmap-cell {
            cursor: default;
            color: white; /* Text color will be white over colored background */
            font-weight: 500;
            white-space: nowrap;
            text-overflow: ellipsis;
            overflow: hidden;
        }
        
        /* Re-used Component Styles (from previous step) */
        .data-source-card, #matrix-output { background-color: var(--surface-color); border-radius: 8px; box-shadow: var(--elevation-low); padding: 20px; transition: box-shadow 0.3s; }
        .data-source-tabs { display: flex; gap: 20px; margin-bottom: 20px; flex-wrap: wrap; }
        .data-source-card { flex: 1 1 300px; text-align: center; cursor: pointer; }
        .data-source-card:hover { box-shadow: var(--elevation-mid); }
        button { background-color: var(--primary-blue); color: var(--surface-color); border: none; padding: 10px 20px; font-size: 14px; font-weight: 500; text-transform: capitalize; cursor: pointer; border-radius: 4px; transition: background-color 0.3s, box-shadow 0.3s; box-shadow: 0 1px 3px rgba(0,0,0,0.1); }
        button:hover { background-color: #3B7DD1; box-shadow: 0 2px 4px rgba(0,0,0,0.15); }
        textarea { border: 1px solid var(--border-color); border-radius: 4px; padding: 12px; height: 120px; margin-bottom: 20px; width: 100%; box-sizing: border-box; font-family: 'Roboto', sans-serif; font-size: 1em; color: var(--text-color); background-color: var(--surface-color); }
        .upload-container { border: 2px dashed var(--border-color); background-color: var(--surface-color); border-radius: 8px; padding: 30px; text-align: center; margin-top: 20px; transition: background-color 0.3s, border-color 0.3s, box-shadow 0.3s; cursor: pointer; position: relative; }
        .upload-container:hover { border-color: var(--primary-blue); background-color: #F8F9FA; box-shadow: var(--elevation-low); }
        .upload-container.drag-over { background-color: #E8F0FE; border-color: var(--primary-blue); box-shadow: 0 0 0 3px rgba(26,115,232,0.2); }
        .upload-container i.fa-file-import { font-size: 3em; color: var(--primary-blue); margin-bottom: 15px; display: block; }
        #file-analytics-card { margin-top: 20px; background-color: var(--surface-color); border-radius: 8px; box-shadow: var(--elevation-low); padding: 20px; border-left: 4px solid var(--google-green); }
        .progress-bar-container { width: 100%; background-color: #eee; border-radius: 4px; margin-top: 15px; overflow: hidden; display: none; align-items: center; height: 35px; box-shadow: inset 0 1px 3px rgba(0,0,0,0.1); position: relative; }
        #llm-output { padding: 20px; border: 1px solid var(--border-color); background-color: #F1F3F4; margin-top: 20px; color: var(--text-color); line-height: 1.6; }
        .progress-bar { height: 100%; background-color: var(--primary-blue); width: 0%; text-align: center; line-height: 35px; color: white; font-size: 12px; transition: width 0.3s ease-out; border-radius: 4px 0 0 4px; white-space: nowrap; overflow: hidden; padding: 0 10px; box-sizing: border-box; }
        .progress-bar-container button { position: absolute; right: 5px; top: 50%; transform: translateY(-50%); z-index: 2; background-color: var(--google-red); padding: 5px 10px; font-size: 0.8em; box-shadow: none; margin-left: auto; }
        #file-preview { display: flex; flex-wrap: wrap; justify-content: flex-start; gap: 10px; margin-top: 20px; padding-top: 15px; border-top: 1px dashed var(--border-color); }
        .file-item { background-color: #F1F3F4; border: 1px solid #DADCE0; border-radius: 16px; padding: 6px 12px; font-size: 0.85em; white-space: nowrap; color: var(--secondary-text); display: flex; align-items: center; gap: 6px; transition: background-color 0.2s, box-shadow 0.2s; cursor: default; }
        .file-item:hover { background-color: #E8F0FE; box-shadow: 0 1px 2px rgba(0,0,0,0.1); }
        .file-item i.fa-file-alt { color: var(--primary-blue); }
        .file-item .remove-file { color: var(--secondary-text); cursor: pointer; font-size: 0.9em; margin-left: 5px; transition: color 0.2s; }
        .file-item .remove-file:hover { color: var(--google-red); }
    </style>
</head>
<body>
<div class="top-header">
    <i class="fas fa-bars" style="margin-right: 20px; font-size: 1.2em;"></i>
    <h1><i class="fas fa-brain"></i> DIY LLM Toolkit</h1>
    <div class="top-header-search">
        <i class="fas fa-search"></i>
        Search the Knowledge Base...
    </div>
    <i class="fas fa-question-circle" style="margin-left: auto; margin-right: 15px; color: rgba(255, 255, 255, 0.7);"></i>
    <i class="fas fa-bell" style="margin-right: 15px; color: rgba(255, 255, 255, 0.7);"></i>
    <div style="width: 30px; height: 30px; background-color: #A0C3FF; border-radius: 50%;"></div>
</div>
<div class="main-content-area">
    <div class="side-nav">
        <div class="nav-item"> <i class="fas fa-home"></i> Overview </div>
        <div class="nav-item active"> <i class="fas fa-database"></i> Data & Tokenization </div>
        <div class="nav-item"> <i class="fas fa-chart-line"></i> Analytics & Metrics </div>
        <div class="nav-item"> <i class="fas fa-cogs"></i> Model Training </div>
        <div class="nav-item"> <i class="fas fa-robot"></i> Text Generation </div>
    </div>
    <div class="content-wrapper">
        <p style="font-size: 0.95em; margin-bottom: 25px;">A modular prototype for training lightweight LLMs, supporting Markov chain fallback and TensorFlow-based attention simulation.</p>
        <div class="mode-toggle">
            <div class="mode-label" id="current-mode-label">
                Current Mode: <strong id="model-mode-name">Markov Chain (Fallback)</strong>
                <br><span>(Switch to Transformer for vector-based generation)</span>
            </div>
            <label class="toggle-switch">
                <input type="checkbox" id="model-mode-toggle" onchange="toggleModelMode(this.checked)">
                <span class="slider"></span>
            </label>
        </div>
        <section id="data-ingestion-section">
            <h2>Data Ingestion & Tokenization</h2>
            
            <div class="data-source-tabs">
                <div class="data-source-card">
                    <h3>Local Files</h3>
                    <i class="fas fa-upload" style="color: var(--primary-blue); font-size: 2.5em; margin-bottom: 16px;"></i>
                    <p style="font-size: 0.9em;">Drag, drop, or select multiple local files for instant processing.</p>
                    <label class="upload-label" for="file-input">Select Local Files</label>
                </div>
                <div class="data-source-card" onclick="connectAwsS3()">
                    <h3>AWS S3 Storage</h3>
                    <i class="fab fa-aws" style="color: #FF9900; font-size: 2.5em; margin-bottom: 16px;"></i>
                    <p style="font-size: 0.9em; font-weight: 500;">Connect to an AWS S3 bucket to stream training data.</p>
                    <button style="background-color: #FF9900;">
                        <i class="fas fa-link"></i> Connect S3 Bucket
                    </button>
                </div>
                <div class="data-source-card">
                    <h3>Kaggle Dataset</h3>
                    <i class="fas fa-cloud-download-alt" style="color: var(--google-green); font-size: 2.5em; margin-bottom: 16px;"></i>
                    <p style="font-size: 0.9em;">Pull data directly from a public Kaggle dataset via API.</p>
                    <button onclick="showAlert('Integration logic for Kaggle data pull goes here.')" style="background-color: var(--google-green);">
                        <i class="fas fa-download"></i> Fetch from Kaggle
                    </button>
                </div>
            </div>
            <div class="upload-container" id="drop-zone">
                 <i class="fas fa-file-import"></i>
                 <p>Drop files here or paste below to train the model.</p>
                 <input type="file" id="file-input" multiple accept=".txt,.csv,.md">
            </div>
            <div id="file-analytics-card">
                <h3>Uploaded Files Overview</h3>
                <div id="file-analytics-summary">0 Files Uploaded (0.0 MB)</div>
                <div id="progress-container" class="progress-bar-container">
                    <div id="progress-bar" class="progress-bar">0%</div>
                    <button onclick="cancelStreaming()"><i class="fas fa-times"></i> Cancel</button>
                </div>
                <div id="file-preview"></div>
                <div style="margin-top: 15px;">
                    <button onclick="tokenizer.exportVocabulary()" style="background-color: #5F6368;"><i class="fas fa-download"></i> Export Vocab</button>
                </div>
            </div>
            <textarea id="text-input" placeholder="... or paste your text corpus directly here."></textarea>
            
            <div style="display: flex; gap: 15px; justify-content: flex-start; margin-bottom: 30px;">
                <button onclick="dataHandler.tokenizeAndBuildMatrix()"><i class="fas fa-list-ol"></i> Tokenize & Preprocess</button>
                <button onclick="miniTransformer.trainOnText()" id="train-button" style="background-color: #3C769D;"><i class="fas fa-bolt"></i> Train Model (Mock)</button>
            </div>
            
        </section>
        <hr class="divider">
        <section id="data-analytics-section" style="display: none;">
            <h2>Data Analytics & Visualization</h2>
            <p style="font-size: 0.9em; margin-bottom: 25px;">These charts update after running the "Tokenize & Preprocess" step.</p>
            <div id="data-analytics-dashboard">
                <div id="token-chart-container" class="dashboard-card">
                    <h3><i class="fas fa-chart-bar"></i> Top 10 Token Frequency</h3>
                    <canvas id="tokenChart"></canvas>
                </div>
                <div id="heatmap-container" class="dashboard-card">
                    <h3><i class="fas fa-th-large"></i> Transition/Attention Heatmap</h3>
                    <div id="transition-heatmap-content">
                        <em>Run tokenization to view Markov transition probabilities.</em>
                    </div>
                </div>
            </div>
            <hr class="divider">
        </section>
        <section id="model-section">
            <h2>Model Configuration & Execution</h2>
            <div id="model-controls-panel">
                <div class="control-group">
                    <label for="max-tokens-input">Max Tokens (Inference)</label>
                    <input type="number" id="max-tokens-input" value="500" min="10">
                </div>
                <div class="control-group">
                    <label for="temperature-input">Temperature (Sampling)</label>
                    <input type="number" id="temperature-input" value="0.8" step="0.1" min="0.1" max="2.0">
                </div>
                <div class="control-group">
                    <label for="embedding-size-input">Embedding Dim (d_model)</label>
                    <input type="number" id="embedding-size-input" value="64" min="16">
                </div>
                <div class="control-group">
                    <label for="epochs-input">Epochs (Training)</label>
                    <input type="number" id="epochs-input" value="10" min="1">
                </div>
                <div class="control-group">
                    <label for="batch-size-input">Batch Size (Training)</label>
                    <input type="number" id="batch-size-input" value="32" min="1">
                </div>
                <div class="control-group">
                    <label for="learning-rate-input">Learning Rate</label>
                    <input type="number" id="learning-rate-input" value="0.001" step="0.0001" min="0.0001">
                </div>
            </div>
            
            <div id="model-dashboard">
                <div id="chart-container">
                    <h3><i class="fas fa-chart-area"></i> Live Loss Curve</h3>
                    <canvas id="lossChart"></canvas>
                </div>
                <div id="metrics-panel">
                    <h3><i class="fas fa-tachometer-alt"></i> Model Metrics</h3>
                    <div class="metric-item">Current Loss: <strong id="metric-loss">N/A</strong></div>
                    <div class="metric-item">Epochs Run: <strong id="metric-epochs">0</strong></div>
                    <div class="metric-item">Vocab Size: <strong id="metric-vocab-size">0</strong></div>
                    <div class="metric-item">Inference Latency: <strong id="metric-latency">N/A</strong></div>
                    <div class="metric-item">Memory Footprint: <strong id="metric-memory">0 MB</strong></div>
                    <button onclick="miniTransformer.saveModel()" style="margin-top: 15px;"><i class="fas fa-save"></i> Save Model Weights</button>
                    <button onclick="miniTransformer.loadModel()" style="margin-top: 10px; background-color: #5F6368;"><i class="fas fa-file-upload"></i> Load Model Weights</button>
                </div>
            </div>
        </section>
        <hr class="divider">
        <section id="generation-section">
            <h2>Text Generation</h2>
            <div style="display: flex; gap: 15px; margin-bottom: 20px;">
                <input type="text" id="prompt-input" placeholder="Enter your prompt word or sentence here..." style="flex-grow: 1; padding: 10px; border: 1px solid var(--border-color); border-radius: 4px;">
                <button onclick="generateTextFromModel()"><i class="fas fa-magic"></i> Generate Text</button>
            </div>
            
            <div id="llm-output">
                <em>Generated text will appear here. Start by tokenizing and training your model.</em>
            </div>
        </section>
    </div>
</div>
<div id="custom-alert" style="position: fixed; top: 0; left: 0; width: 100%; height: 100%; background: rgba(0,0,0,0.5); display: none; justify-content: center; align-items: center; z-index: 1000;">
    <div style="background: white; padding: 25px; border-radius: 8px; box-shadow: var(--elevation-mid); max-width: 400px;">
        <h3 id="alert-title" style="margin-top: 0; color: var(--primary-blue);">Alert</h3>
        <p id="alert-message"></p>
        <button onclick="document.getElementById('custom-alert').style.display='none'" style="float: right;">OK</button>
    </div>
</div>
<script>
    // #region Phase 1: Modular Architecture & Config (config.json, app.js, utils.js)
    const CONFIG = {
        modelMode: 'MARKOV', // 'MARKOV' or 'TRANSFORMER'
        maxTokens: 500,
        temperature: 0.8,
        embeddingDim: 64,
        numHeads: 4, // NEW: Number of attention heads
        ffnDim: 128, // NEW: Feed-forward dimension
        train: {
            epochs: 10,
            batchSize: 32,
            learningRate: 0.001
        }
    };
    
    // Model configuration constants
    const SEQUENCE_LENGTH = 10; // Input sequence length for the transformer
    const UNK_TOKEN_ID = 0;     // ID reserved for unknown/padding token
    let lossChart = null;
    let tokenChart = null;
    // --- UPDATED: Holds the function to cancel the stream ---
    let currentStreamController = null; 
    
    // --- Utility Functions (utils.js) ---
    function showAlert(message, title = 'Notification') {
        document.getElementById('alert-title').textContent = title;
        document.getElementById('alert-message').innerHTML = message;
        document.getElementById('custom-alert').style.display = 'flex';
    }
    /**
     * Initializes the loss chart (Line Chart for Training Metrics).
     */
    function initializeLossChart() {
        const ctx = document.getElementById('lossChart').getContext('2d');
        if (lossChart) lossChart.destroy();
        lossChart = new Chart(ctx, {
            type: 'line',
            data: {
                labels: [],
                datasets: [{
                    label: 'Training Loss',
                    data: [],
                    borderColor: 'rgb(26, 115, 232)',
                    backgroundColor: 'rgba(26, 115, 232, 0.1)',
                    tension: 0.4
                }]
            },
            options: {
                responsive: true,
                plugins: { legend: { display: false } },
                scales: {
                    y: { beginAtZero: true, title: { display: true, text: 'Loss' } },
                    x: { title: { display: true, text: 'Epoch' } }
                }
            }
        });
    }
    
    /**
     * Initializes the token chart (Bar Chart for Data Analysis).
     */
    function initializeTokenChart() {
        const ctx = document.getElementById('tokenChart').getContext('2d');
        if (tokenChart) tokenChart.destroy();
        tokenChart = new Chart(ctx, {
            type: 'bar',
            data: {
                labels: [],
                datasets: [{
                    label: 'Token Count',
                    data: [],
                    backgroundColor: 'rgba(15, 157, 88, 0.6)', // Google Green
                    borderColor: 'rgb(15, 157, 88)',
                    borderWidth: 1
                }]
            },
            options: {
                responsive: true,
                plugins: { legend: { display: false } },
                indexAxis: 'y', // Horizontal bars
                scales: {
                    x: { beginAtZero: true, title: { display: true, text: 'Frequency' } },
                    y: { ticks: { autoSkip: false } }
                }
            }
        });
    }
    // --- Event System (Lightweight Observer Pattern) ---
    const state = new Proxy({
        mode: CONFIG.modelMode,
        vocabSize: 0,
        currentLoss: 'N/A',
        epochsRun: 0,
        latency: 'N/A',
        isTraining: false, // NEW: Track training state
    }, {
        set(obj, prop, value) {
            obj[prop] = value;
            updateUI(prop, value);
            return true;
        }
    });
    /**
     * Updates UI elements based on state changes.
     */
    function updateUI(prop, value) {
        switch (prop) {
            case 'mode':
                document.getElementById('model-mode-name').textContent = value === 'MARKOV' ? 'Markov Chain (Fallback)' : 'MiniTransformer (TF.js)';
                document.getElementById('current-mode-label').style.borderLeftColor = value === 'MARKOV' ? '#ccc' : 'var(--primary-blue)';
                document.getElementById('llm-output').innerHTML = `<em>Switched to ${value} mode. Re-run generation.</em>`;
                break;
            case 'vocabSize':
                document.getElementById('metric-vocab-size').textContent = value.toLocaleString();
                break;
            case 'currentLoss':
                document.getElementById('metric-loss').textContent = typeof value === 'number' ? value.toFixed(4) : value;
                break;
            case 'epochsRun':
                document.getElementById('metric-epochs').textContent = value.toLocaleString();
                break;
            case 'latency':
                document.getElementById('metric-latency').textContent = value;
                break;
            case 'isTraining':
                const trainButton = document.getElementById('train-button');
                trainButton.disabled = value;
                trainButton.textContent = value ? 'Training...' : 'Train Model (Mock)';
                trainButton.style.backgroundColor = value ? '#FF9900' : '#3C769D';
                break;
            default:
                break;
        }
    }
    function toggleModelMode(isChecked) {
        state.mode = isChecked ? 'TRANSFORMER' : 'MARKOV';
        // Hide/Show training controls based on mode
        const displayStyle = state.mode === 'TRANSFORMER' ? 'grid' : 'none';
        
        // Only show controls if in Transformer mode
        document.getElementById('model-controls-panel').style.display = displayStyle;
        document.getElementById('model-dashboard').style.display = displayStyle;
        
        // If switching to TRANSFORMER, ensure chart is initialized
        if (state.mode === 'TRANSFORMER' && !lossChart) {
             initializeLossChart();
        }
        
        // Update the train button text for consistency
        const trainButton = document.getElementById('train-button');
        if (state.mode === 'TRANSFORMER') {
            trainButton.innerHTML = '<i class="fas fa-bolt"></i> Train Model (TF.js)';
        } else {
            trainButton.innerHTML = '<i class="fas fa-bolt"></i> Train Model (Mock)';
        }
    }
    
    // --- UI Controls Synchronization ---
    document.getElementById('max-tokens-input').addEventListener('input', (e) => CONFIG.maxTokens = parseInt(e.target.value));
    document.getElementById('temperature-input').addEventListener('input', (e) => CONFIG.temperature = parseFloat(e.target.value));
    document.getElementById('embedding-size-input').addEventListener('input', (e) => CONFIG.embeddingDim = parseInt(e.target.value));
    document.getElementById('epochs-input').addEventListener('input', (e) => CONFIG.train.epochs = parseInt(e.target.value));
    document.getElementById('batch-size-input').addEventListener('input', (e) => CONFIG.train.batchSize = parseInt(e.target.value));
    document.getElementById('learning-rate-input').addEventListener('input', (e) => CONFIG.train.learningRate = parseFloat(e.target.value));
    // #endregion Phase 1
    // #region Phase 2: Data Preprocessing & Tokenization (dataHandler.js, tokenizer.js)
    /**
     * Phase 2 Deliverable: Placeholder Byte-Pair Encoding (BPE) or WordPiece Tokenizer.
     */
    class Tokenizer {
        constructor() {
            this.vocab = {}; 
            this.idToToken = {};
            this.tokenCounts = {}; 
            this.nextId = 1; // Start IDs at 1, reserving 0 for UNK/Padding
        }
        /**
         * Cleans text (lower, punctuation removal)
         */
        cleanText(text) {
            // Lowercase and split text by word (simple tokenization)
            return text.toLowerCase().replace(/[.,\/#!$%\^&\*;:{}=\-_`~()]/g, ' ').replace(/\s{2,}/g, ' ');
        }
        /**
         * Builds the vocabulary and token frequencies from the corpus (Mock BPE training)
         */
        train(corpus) {
            const cleanedCorpus = this.cleanText(corpus);
            const words = cleanedCorpus.split(/\s+/).filter(w => w.length > 0);
            
            // Reset state
            this.vocab = {};
            this.idToToken = {};
            this.tokenCounts = {};
            this.nextId = 1;
            words.forEach(word => {
                if (!this.vocab[word]) {
                    this.vocab[word] = this.nextId;
                    this.idToToken[this.nextId] = word;
                    this.nextId++;
                }
                this.tokenCounts[word] = (this.tokenCounts[word] || 0) + 1;
            });
            // Add UNK/Padding token at ID 0 for model input
            this.idToToken[UNK_TOKEN_ID] = '[PAD]';
            
            state.vocabSize = Object.keys(this.vocab).length;
            showAlert(`Mock Tokenizer trained. Vocab size: ${state.vocabSize} (plus 1 reserved ID for padding)`, 'Tokenization Complete');
        }
        /**
         * Encodes text into an array of token IDs.
         */
        encode(text) {
            if (state.vocabSize === 0) return [];
            const cleanedText = this.cleanText(text);
            const words = cleanedText.split(/\s+/).filter(w => w.length > 0);
            // Returns ID or UNK_TOKEN_ID (0) if word is not found
            return words.map(word => this.vocab[word] || UNK_TOKEN_ID); 
        }
        
        /**
         * Decodes an array of token IDs back into a string.
         */
        decode(ids) {
            return ids.map(id => this.idToToken[id] || '[UNK]').join(' ');
        }
        
        /**
         * Renders the top N token frequencies for the bar chart.
         */
        getTopTokenFrequencies(n = 10) {
            const sortedTokens = Object.entries(this.tokenCounts)
                .sort(([, countA], [, countB]) => countB - countA)
                .slice(0, n);
            
            return {
                labels: sortedTokens.map(([token]) => token),
                data: sortedTokens.map(([, count]) => count)
            };
        }

        exportVocabulary() {
            const vocabContent = JSON.stringify(this.idToToken, null, 2);
            const blob = new Blob([vocabContent], { type: 'application/json' });
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            a.download = 'llm_vocab.json';
            document.body.appendChild(a);
            a.click();
            document.body.removeChild(a);
            URL.revokeObjectURL(url);
            showAlert('The current vocabulary has been exported as **llm_vocab.json**.', 'Export Successful');
        }
    }
    
    /**
     * Phase 2 Deliverable: Handles I/O, file processing, and builds Markov matrix.
     */
    class DataHandler {
        constructor(tokenizer) {
            this.tokenizer = tokenizer;
            this.corpusText = "";
            this.tokenIDs = [];
            this.transitionMatrix = null;
            this.uploadedFiles = [];
            this.totalSizeMB = 0;
            // Initialize event listeners
            this.setupListeners();
            initializeTokenChart(); // Initialize the token chart immediately
        }
        
        setupListeners() {
            // Local file input change handler
            document.getElementById('file-input').addEventListener('change', (e) => {
                this.handleFiles(e.target.files);
            });
            // Text area change listener (for real-time update mock)
            document.getElementById('text-input').addEventListener('input', (e) => {
                this.corpusText = e.target.value;
            });
            // Drop zone listeners
            const dropZone = document.getElementById('drop-zone');
            ['dragenter', 'dragover', 'dragleave', 'drop'].forEach(eventName => {
                dropZone.addEventListener(eventName, this.preventDefaults, false);
            });
            dropZone.addEventListener('dragenter', () => dropZone.classList.add('drag-over'), false);
            dropZone.addEventListener('dragleave', () => dropZone.classList.remove('drag-over'), false);
            dropZone.addEventListener('drop', (e) => {
                dropZone.classList.remove('drag-over');
                this.handleFiles(e.dataTransfer.files);
            }, false);
        }
        
        preventDefaults(e) {
            e.preventDefault();
            e.stopPropagation();
        }

        /**
         * Handles local file selection/drop.
         */
        handleFiles(files) {
            const progressBarContainer = document.getElementById('progress-container');
            const progressBar = document.getElementById('progress-bar');
            
            if (files.length === 0) return;
            
            progressBarContainer.style.display = 'flex';
            progressBar.style.width = '0%';
            progressBar.textContent = '0%';
            this.corpusText = "";
            this.uploadedFiles = [];
            this.totalSizeMB = 0;
            document.getElementById('file-preview').innerHTML = '';

            let filePromises = [];
            
            for (let i = 0; i < files.length; i++) {
                const file = files[i];
                const fileSizeMB = file.size / (1024 * 1024);
                this.totalSizeMB += fileSizeMB;

                // Add to uploaded files list and preview
                this.addFileToPreview(file);

                filePromises.push(new Promise((resolve) => {
                    const reader = new FileReader();
                    reader.onload = (e) => {
                        this.corpusText += e.target.result + " ";
                        // Update progress bar
                        const progress = ((i + 1) / files.length) * 100;
                        progressBar.style.width = progress.toFixed(0) + '%';
                        progressBar.textContent = `${progress.toFixed(0)}% - Reading ${file.name}`;
                        
                        resolve();
                    };
                    // Handle cancellation via the global controller
                    currentStreamController = () => {
                        reader.abort();
                        resolve(); // Resolve promise to prevent blocking
                    };
                    reader.readAsText(file);
                }));
            }

            Promise.all(filePromises).then(() => {
                progressBarContainer.style.display = 'none';
                document.getElementById('text-input').value = this.corpusText.trim();
                showAlert(`Successfully loaded ${files.length} files (${this.totalSizeMB.toFixed(2)} MB). Ready for tokenization.`, 'File Load Complete');
                this.updateSummary();
            });
        }
        
        /**
         * Adds a file item to the visual preview list. Used by both local and S3 mock.
         */
        addFileToPreview(fileInfo) {
            const preview = document.getElementById('file-preview');
            const fileItem = document.createElement('div');
            const sizeString = fileInfo.size ? `${parseFloat(fileInfo.size).toFixed(2)} MB` : 'S3 Mock';

            fileItem.className = 'file-item';
            fileItem.innerHTML = `<i class="fas fa-file-alt"></i> <span>${fileInfo.name}</span> <span style="font-size: 0.8em;">(${sizeString})</span>`;
            
            // Add to internal list
            this.uploadedFiles.push(fileInfo);
            this.totalSizeMB += parseFloat(fileInfo.size) || 0;
            
            // Add remove button logic (Mock)
            const removeIcon = document.createElement('i');
            removeIcon.className = 'fas fa-times remove-file';
            removeIcon.onclick = () => {
                 fileItem.remove();
                 showAlert(`Removed file **${fileInfo.name}**. You must re-run tokenization.`, 'File Removed');
                 // Note: Full array manipulation is omitted for prototype simplicity
            };
            fileItem.appendChild(removeIcon);
            
            preview.appendChild(fileItem);
            this.updateSummary();
        }

        updateSummary() {
            document.getElementById('file-analytics-summary').textContent = 
                `${this.uploadedFiles.length} Files Uploaded (${this.totalSizeMB.toFixed(2)} MB)`;
        }
        
        /**
         * Main function to run the data pipeline: Tokenize, Analyze, and Build Matrix.
         */
        tokenizeAndBuildMatrix() {
            const corpus = document.getElementById('text-input').value.trim() || this.corpusText.trim();
            if (!corpus) {
                showAlert('Please provide a text corpus (paste text, upload files, or stream from S3 mock) before tokenization.', 'Input Required');
                return;
            }

            // 1. Train Tokenizer & Encode
            this.tokenizer.train(corpus);
            this.tokenIDs = this.tokenizer.encode(corpus);
            
            // 2. Build Markov Transition Matrix (or mock for Transformer mode)
            if (state.mode === 'MARKOV') {
                 this.buildMarkovTransitionMatrix(this.tokenIDs);
            } else {
                 this.transitionMatrix = null; // Clear matrix for TF.js mode
            }
            
            // 3. Update Visualizations
            this.updateTokenChart();
            this.updateHeatmap();
            
            // Show analytics section
            document.getElementById('data-analytics-section').style.display = 'block';
            
            showAlert(`Tokenization and Preprocessing complete. Total tokens: **${this.tokenIDs.length.toLocaleString()}**`, 'Preprocessing Complete');
        }
        
        /**
         * Builds a simple Markov chain transition matrix (Token ID -> next Token ID counts).
         */
        buildMarkovTransitionMatrix(tokenIDs) {
            const size = state.vocabSize + 1; // +1 for UNK/Padding
            // Initialize matrix with zeros
            let matrix = Array(size).fill(0).map(() => Array(size).fill(0));
            let rowSums = Array(size).fill(0);

            for (let i = 0; i < tokenIDs.length - 1; i++) {
                const currentId = tokenIDs[i];
                const nextId = tokenIDs[i+1];
                
                // Ensure IDs are within bounds (or use UNK_TOKEN_ID if they somehow exceed)
                const fromId = currentId < size ? currentId : UNK_TOKEN_ID;
                const toId = nextId < size ? nextId : UNK_TOKEN_ID;
                
                matrix[fromId][toId]++;
                rowSums[fromId]++;
            }

            // Normalize matrix to get probabilities
            for (let i = 0; i < size; i++) {
                if (rowSums[i] > 0) {
                    for (let j = 0; j < size; j++) {
                        matrix[i][j] /= rowSums[i];
                    }
                }
            }
            
            this.transitionMatrix = matrix;
        }

        updateTokenChart() {
            const { labels, data } = this.tokenizer.getTopTokenFrequencies(10);
            tokenChart.data.labels = labels;
            tokenChart.data.datasets[0].data = data;
            tokenChart.update();
        }

        updateHeatmap() {
            const heatmapContent = document.getElementById('transition-heatmap-content');
            if (state.mode === 'TRANSFORMER') {
                heatmapContent.innerHTML = `<em>Transition Heatmap is used for Markov analysis. Transformer mode relies on vector-based Attention Weights (not shown here).</em>`;
                return;
            }
            if (!this.transitionMatrix) {
                heatmapContent.innerHTML = `<em>Run tokenization to view Markov transition probabilities.</em>`;
                return;
            }

            const size = state.vocabSize + 1;
            let html = '<table><thead><tr><th>Next $\\rightarrow$</th>';
            // Header row (Next Token)
            for (let j = 1; j < Math.min(size, 10); j++) {
                 html += `<th>${this.tokenizer.idToToken[j]}</th>`;
            }
            html += '</tr></thead><tbody>';

            // Data rows (Current Token)
            for (let i = 1; i < Math.min(size, 10); i++) {
                const token = this.tokenizer.idToToken[i];
                html += `<tr><th>${token}</th>`;
                for (let j = 1; j < Math.min(size, 10); j++) {
                    const prob = this.transitionMatrix[i][j] || 0;
                    // Scale color from white (0) to primary-blue (1)
                    const color = `rgba(26, 115, 232, ${prob})`; 
                    html += `<td class="heatmap-cell" style="background-color: ${color};" title="P(${this.tokenizer.idToToken[j]} | ${token}) = ${prob.toFixed(3)}">${(prob * 100).toFixed(1)}%</td>`;
                }
                html += '</tr>';
            }
            html += '</tbody></table>';
            
            heatmapContent.innerHTML = html;
        }
        
    }
    // Instantiate the global data objects
    const tokenizer = new Tokenizer();
    const dataHandler = new DataHandler(tokenizer);
    // #endregion Phase 2
    
    // #region Phase 4: S3 Connector (Finished Implementation)
    
    /**
     * Helper function to generate a random file size in MB for the mock stream.
     */
    function getRandomFileSizeMB() {
        return (Math.random() * 5 + 1).toFixed(2); // 1.00 MB to 6.00 MB
    }

    /**
     * Helper function to simulate a chunked S3 download stream and aggregate text.
     */
    function mockS3DataStream(fileNames, onComplete) {
        const totalFiles = fileNames.length;
        let filesProcessed = 0;
        let accumulatedText = "";
        
        // Reset the progress bar for the new operation
        const progressContainer = document.getElementById('progress-container');
        const progressBar = document.getElementById('progress-bar');
        progressContainer.style.display = 'flex';
        progressBar.style.width = '0%';
        progressBar.textContent = '0%';
        
        // Clear previous files and summary before streaming new ones
        dataHandler.uploadedFiles = [];
        dataHandler.totalSizeMB = 0;
        document.getElementById('file-preview').innerHTML = '';
        dataHandler.updateSummary();

        // Simulate streaming and processing each file
        const processNextFile = () => {
            if (filesProcessed >= totalFiles) {
                onComplete(accumulatedText);
                progressContainer.style.display = 'none';
                // Reset the global controller after completion
                currentStreamController = null; 
                return;
            }

            const fileName = fileNames[filesProcessed];
            const fileSize = getRandomFileSizeMB(); 
            const numChunks = 10;
            let currentChunk = 0;
            
            const updateProgress = () => {
                if (filesProcessed >= totalFiles) return; // Check for external cancellation
                
                currentChunk++;
                const overallProgress = ((filesProcessed * numChunks + currentChunk) / (totalFiles * numChunks)) * 100;
                
                // Update UI with overall progress
                progressBar.style.width = overallProgress.toFixed(0) + '%';
                progressBar.textContent = `${overallProgress.toFixed(0)}% (${fileName} - Chunk ${currentChunk}/${numChunks})`;
                
                // Simulate adding a chunk of text
                accumulatedText += `This is a streamed data chunk for file ${fileName} with size ${fileSize}MB. `;

                if (currentChunk >= numChunks) {
                    // File finished processing
                    filesProcessed++;
                    // Add the file to the preview list
                    dataHandler.addFileToPreview({ name: fileName, size: fileSize });
                    
                    // Move to the next file after a slight delay
                    setTimeout(processNextFile, 100); 
                } else {
                    // Continue streaming chunks
                    setTimeout(updateProgress, 50); 
                }
            };

            updateProgress();
        };

        processNextFile();
        
        // Return a function to allow cancellation (for the 'Cancel' button)
        return () => { 
            filesProcessed = totalFiles; // Force exit
            progressContainer.style.display = 'none';
            showAlert('AWS S3 data streaming was cancelled by the user.', 'Operation Cancelled');
            currentStreamController = null;
        };
    }

    /**
     * Phase 4: Implementation of the AWS S3 Connector mock.
     * This function initiates the mock stream and connects its output to the training pipeline.
     */
    function connectAwsS3() {
        const bucketName = 'llm-training-data-001';
        // Mock list of files we would stream
        const mockFiles = ['legal_corpus_1.txt', 'patent_abstracts_2.csv', 'tech_docs_3.md', 'qa_logs_4.txt'];
        
        const message = `
            Attempting to connect to S3 Bucket: **${bucketName}**...
            <br><br>
            Simulating retrieval of **${mockFiles.length}** training files. The data will be added to the input field and tokenization will start automatically.
        `;
        
        showAlert(message, 'Initiating S3 Data Stream Mock');
        
        // Start the mock stream
        currentStreamController = mockS3DataStream(
            mockFiles, 
            // onComplete callback: Connects the data to the rest of the system
            (aggregatedText) => {
                // 1. Put the aggregated text into the main input box
                const textInput = document.getElementById('text-input');
                textInput.value = aggregatedText.trim();
                
                // 2. Automatically kick off the tokenization and preprocessing process
                dataHandler.tokenizeAndBuildMatrix();
                
                showAlert(`Successfully streamed ${dataHandler.uploadedFiles.length} files from S3 mock. Tokenization has started.`, 'S3 Stream Complete');
            }
        );
    }
    
    /**
     * Universal function to cancel the current streaming/upload operation.
     */
    function cancelStreaming() {
        if (currentStreamController) {
            currentStreamController(); // Execute the cancellation function
        }
    }
    // #endregion Phase 4
    
    // #region Phase 3/4: Model Logic (MarkovChain.js, MiniTransformer.js)
    
    /**
     * Phase 3 Deliverable: Placeholder for the Markov Chain Generation Logic.
     */
    class MarkovChain {
        constructor(tokenizer, dataHandler) {
            this.tokenizer = tokenizer;
            this.dataHandler = dataHandler;
        }

        generate(prompt) {
            const matrix = this.dataHandler.transitionMatrix;
            if (!matrix) return 'Error: Markov transition matrix not built. Run Tokenize & Preprocess first.';
            
            const promptWords = this.tokenizer.cleanText(prompt).split(/\s+/).filter(w => w.length > 0);
            if (promptWords.length === 0) {
                 return 'Error: Please enter a prompt for the Markov model.';
            }

            const startToken = promptWords[promptWords.length - 1];
            let currentId = this.tokenizer.vocab[startToken] || UNK_TOKEN_ID;
            let outputIds = this.tokenizer.encode(prompt);
            
            for (let i = 0; i < CONFIG.maxTokens; i++) {
                const probabilities = matrix[currentId];
                if (!probabilities) break; // End of chain
                
                // Simple weighted random sampling (no temperature simulation for Markov)
                let sum = 0;
                let r = Math.random();
                let nextId = UNK_TOKEN_ID;
                
                for (let j = 0; j < probabilities.length; j++) {
                    sum += probabilities[j];
                    if (r <= sum) {
                        nextId = j;
                        break;
                    }
                }
                
                if (nextId === UNK_TOKEN_ID) break; // Stop on UNK
                
                outputIds.push(nextId);
                currentId = nextId;
            }
            
            return this.tokenizer.decode(outputIds);
        }
    }
    
    /**
     * Phase 4 Deliverable: Placeholder for the Mini-Transformer (TF.js based).
     */
    class MiniTransformer {
        constructor(tokenizer, dataHandler) {
            this.tokenizer = tokenizer;
            this.dataHandler = dataHandler;
            this.model = null;
            this.lossHistory = [];
        }

        // --- Model Initialization (Mock) ---
        buildModel() {
            const vocabSize = state.vocabSize + 1;
            const d_model = CONFIG.embeddingDim;
            const numHeads = CONFIG.numHeads;
            const ffnDim = CONFIG.ffnDim;
            const seqLen = SEQUENCE_LENGTH;

            // Simple Feed-Forward Model Mock (True Transformer is complex for a simple script)
            this.model = tf.sequential({
                layers: [
                    // Mock Embedding Layer (Input layer)
                    tf.layers.dense({ units: d_model, inputShape: [seqLen, vocabSize], activation: 'relu' }),
                    // Mock Attention Block (Dense Layer)
                    tf.layers.dense({ units: ffnDim, activation: 'relu' }),
                    // Mock Output Layer
                    tf.layers.dense({ units: vocabSize, activation: 'softmax' })
                ]
            });
            
            // Compile with user-defined learning rate
            this.model.compile({
                optimizer: tf.train.adam(CONFIG.train.learningRate),
                loss: 'categoricalCrossentropy',
                metrics: ['accuracy']
            });
            
            showAlert(`Mock MiniTransformer initialized. Vocab Size: ${vocabSize}, Embedding Dim: ${d_model}`, 'Model Ready');
            console.log('Mock Model Summary (TF.js):', this.model.summary());
        }

        // --- Training (Mock) ---
        async trainOnText() {
            if (state.isTraining) return;
            state.isTraining = true;
            this.lossHistory = [];
            state.epochsRun = 0;
            initializeLossChart();

            const tokenIDs = this.dataHandler.tokenIDs;
            if (tokenIDs.length < SEQUENCE_LENGTH * 2) {
                showAlert('Corpus is too short. Need more text to train a Transformer model.', 'Training Error');
                state.isTraining = false;
                return;
            }

            if (!this.model) this.buildModel();
            
            // Mock Data Generator: Creates one-hot encoded sequence-to-next-token pairs
            // In a real scenario, this would involve complex batching and masking.
            const generateMockData = (epochs) => {
                let xs = []; // Input sequences
                let ys = []; // Target (next) token
                for (let i = 0; i < tokenIDs.length - SEQUENCE_LENGTH; i++) {
                    const inputSeq = tokenIDs.slice(i, i + SEQUENCE_LENGTH);
                    const targetToken = tokenIDs[i + SEQUENCE_LENGTH];
                    
                    // Mock: Create a 2D array [SEQUENCE_LENGTH, vocabSize] for each input
                    const inputTensor = tf.oneHot(inputSeq, state.vocabSize + 1).arraySync();
                    // Mock: Create a 1D array [vocabSize] for the one-hot target
                    const targetTensor = tf.oneHot(targetToken, state.vocabSize + 1).arraySync();
                    
                    xs.push(inputTensor);
                    ys.push(targetTensor);
                }
                // Convert lists to Tensors
                return { 
                    xs: tf.tensor3d(xs, [xs.length, SEQUENCE_LENGTH, state.vocabSize + 1]), 
                    ys: tf.tensor2d(ys, [ys.length, state.vocabSize + 1]) 
                };
            };
            
            const { xs, ys } = generateMockData();

            showAlert(`Starting Mock Transformer Training for ${CONFIG.train.epochs} epochs...`, 'Training Started');
            
            // --- Mock Training Loop ---
            for (let i = 0; i < CONFIG.train.epochs; i++) {
                 if (!state.isTraining) break; // Check for external cancellation/stop
                 
                 const history = await this.model.fit(xs, ys, {
                     epochs: 1, // Run one epoch at a time for live update
                     batchSize: CONFIG.train.batchSize,
                     shuffle: true,
                     callbacks: {
                         onEpochEnd: (epoch, logs) => {
                             const loss = logs.loss;
                             this.lossHistory.push(loss);
                             state.currentLoss = loss;
                             state.epochsRun = i + 1;
                             
                             // Update Chart
                             if (lossChart) {
                                 lossChart.data.labels.push(i + 1);
                                 lossChart.data.datasets[0].data.push(loss);
                                 lossChart.update('none'); // 'none' for instant update
                             }
                         }
                     }
                 });
                 // Small delay to simulate real-time updates
                 await new Promise(resolve => setTimeout(resolve, 50));
            }
            
            xs.dispose();
            ys.dispose();
            
            state.isTraining = false;
            showAlert(`Mock Transformer Training complete! Final Loss: ${state.currentLoss}`, 'Training Finished');
        }

        // --- Inference (Mock) ---
        async generate(prompt) {
            if (!this.model) {
                 return 'Error: MiniTransformer model not trained or loaded.';
            }
            
            // Start timer for latency metric
            const startTime = performance.now();
            
            let outputIDs = this.tokenizer.encode(prompt);
            let currentIDs = outputIDs.slice(-SEQUENCE_LENGTH); // Use last SEQUENCE_LENGTH tokens as initial input

            for (let i = 0; i < CONFIG.maxTokens; i++) {
                 if (currentIDs.length < SEQUENCE_LENGTH) {
                    // Padding: Prepends UNK_TOKEN_ID (0)
                    currentIDs = Array(SEQUENCE_LENGTH - currentIDs.length).fill(UNK_TOKEN_ID).concat(currentIDs);
                 }
                 
                 // 1. Prepare input tensor
                 const inputTensorArray = tf.oneHot(currentIDs.slice(-SEQUENCE_LENGTH), state.vocabSize + 1).arraySync();
                 const inputTensor = tf.tensor3d([inputTensorArray], [1, SEQUENCE_LENGTH, state.vocabSize + 1]);
                 
                 // 2. Mock prediction
                 const prediction = this.model.predict(inputTensor);
                 
                 // 3. Apply Temperature Sampling
                 const logits = prediction.dataSync(); // Get raw array of probabilities (logits in real model)
                 prediction.dispose();
                 inputTensor.dispose();

                 // Simple Softmax + Temperature sampling (not strictly logit-based but simulates)
                 const nextId = this.sampleWithTemperature(logits, CONFIG.temperature);
                 
                 if (nextId === UNK_TOKEN_ID) break; // Stop on UNK

                 outputIDs.push(nextId);
                 currentIDs.push(nextId);
                 
                 // Stop if max tokens reached
                 if (outputIDs.length >= CONFIG.maxTokens) break;
                 
                 // Optional: yield/delay for visible streaming effect (omitted for brevity)
                 await new Promise(resolve => setTimeout(resolve, 1)); 
            }
            
            const endTime = performance.now();
            state.latency = `${(endTime - startTime).toFixed(2)} ms`;
            
            return this.tokenizer.decode(outputIDs);
        }
        
        // --- Sampling ---
        sampleWithTemperature(probabilities, temperature) {
            const size = probabilities.length;
            
            // Normalize probabilities (already softmaxed in mock, but rescale for safety)
            let sum = probabilities.reduce((a, b) => a + b, 0);
            let scaledProbs = probabilities.map(p => p / sum);
            
            // Apply temperature scaling (simplified mock, usually applied to logits before softmax)
            if (temperature !== 1.0) {
                 scaledProbs = scaledProbs.map(p => Math.pow(p, 1 / temperature));
                 const scaledSum = scaledProbs.reduce((a, b) => a + b, 0);
                 scaledProbs = scaledProbs.map(p => p / scaledSum);
            }
            
            // Perform Categorical Sampling
            let r = Math.random();
            let accumulator = 0;
            for (let i = 0; i < size; i++) {
                 accumulator += scaledProbs[i];
                 if (r < accumulator) {
                     return i; // Return the token ID
                 }
            }
            return UNK_TOKEN_ID; // Fallback to UNK/PAD
        }

        // --- Utility ---
        saveModel() {
            // Mock: In a real TF.js app, this saves to IndexedDB or downloads files
            showAlert('Model weights have been successfully saved (mock function).', 'Model Save');
        }

        loadModel() {
            // Mock: Re-initializes model state
            this.buildModel(); 
            state.epochsRun = 5; // Pretend 5 epochs were run
            state.currentLoss = 0.5234;
            showAlert('Model weights have been successfully loaded (mock function).', 'Model Load');
        }
    }
    
    // Instantiate the global model objects
    const markovModel = new MarkovChain(tokenizer, dataHandler);
    const miniTransformer = new MiniTransformer(tokenizer, dataHandler);
    
    // --- Main Generation Function ---
    async function generateTextFromModel() {
        const prompt = document.getElementById('prompt-input').value.trim();
        const outputElement = document.getElementById('llm-output');
        outputElement.innerHTML = '<em>Generating...</em>';
        
        if (!prompt) {
             outputElement.innerHTML = '<em>Please enter a prompt.</em>';
             showAlert('Please enter a prompt in the input field above.', 'Prompt Required');
             return;
        }

        let generatedText = "";
        
        if (state.mode === 'MARKOV') {
            generatedText = markovModel.generate(prompt);
        } else {
            generatedText = await miniTransformer.generate(prompt);
        }
        
        outputElement.innerHTML = `<p style="font-weight: 500; color: var(--text-color);">Prompt: ${prompt}</p>${generatedText}`;
    }
    // #endregion Phase 3/4
    
    // Initial Setup
    document.addEventListener('DOMContentLoaded', () => {
         // Run toggle once to set initial state (Markov default)
         toggleModelMode(document.getElementById('model-mode-toggle').checked); 
    });
</script>
</body>
</html>
