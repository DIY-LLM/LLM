<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DIY LLM Toolkit | Modular Prototype</title>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.10.0/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js@3.7.1/dist/chart.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/aws-sdk/2.1520.0/aws-sdk.min.js"></script>
    
    <style>
        /* --- Google Cloud/Material Design Variables --- */
        :root {
            --primary-blue: #1A73E8;
            --header-blue: #1A2E44;
            --nav-panel-color: #F1F3F4;
            --active-item-color: #E8F0FE;
            --surface-color: #FFFFFF;
            --background-color: #F8F9FA;
            --text-color: #202124;
            --secondary-text: #5F6368;
            --border-color: #DADCE0;
            --google-red: #DB4437;
            --google-green: #0F9D58;
            --google-orange: #F4B400;
            --elevation-low: 0 1px 2px 0 rgba(0,0,0,0.1), 0 1px 3px 0 rgba(0,0,0,0.06);
            --elevation-mid: 0 2px 4px 0 rgba(0,0,0,0.1), 0 2px 5px 0 rgba(0,0,0,0.08);
        }
        /* --- Base Layout --- */
        body {
            font-family: 'Roboto', sans-serif;
            background-color: var(--background-color);
            color: var(--text-color);
            margin: 0;
            padding: 0;
            display: flex;
            flex-direction: column;
            min-height: 100vh;
        }
        .top-header {
            background-color: var(--header-blue);
            color: var(--surface-color);
            padding: 10px 20px;
            display: flex;
            align-items: center;
            box-shadow: var(--elevation-low);
            z-index: 10;
        }
        .top-header h1 { font-size: 1.5em; font-weight: 400; margin: 0 30px 0 10px; white-space: nowrap; }
        .top-header h1 i { color: #4285F4; margin-right: 8px; }
        .main-content-area { display: flex; flex-grow: 1; }
        .side-nav {
            width: 250px;
            background-color: var(--surface-color);
            border-right: 1px solid var(--border-color);
            padding: 15px 0;
            flex-shrink: 0;
        }
        .nav-item { padding: 10px 20px; color: var(--secondary-text); font-size: 0.95em; cursor: pointer; transition: background-color 0.2s; }
        .nav-item.active { background-color: var(--active-item-color); color: var(--primary-blue); border-left: 3px solid var(--primary-blue); font-weight: 500; padding-left: 17px; }
        .nav-item i { margin-right: 12px; font-size: 1.1em; width: 20px; text-align: center; }
        .content-wrapper { flex-grow: 1; padding: 30px; max-width: 1000px; }
        h2 { color: var(--text-color); font-weight: 500; font-size: 1.6em; margin-top: 0; margin-bottom: 20px; }
        .divider { margin: 30px 0; border: none; border-top: 1px solid var(--border-color); }
        
        /* Model Mode Toggle */
        .mode-selector {
            display: flex;
            flex-wrap: wrap;
            gap: 15px;
            margin-bottom: 25px;
        }
        .mode-card {
            flex: 1 1 200px;
            background-color: var(--surface-color);
            padding: 20px;
            border-radius: 8px;
            box-shadow: var(--elevation-low);
            cursor: pointer;
            border: 2px solid transparent;
            transition: all 0.2s;
        }
        .mode-card.selected {
            border-color: var(--primary-blue);
            box-shadow: 0 0 0 3px rgba(26,115,232,0.3);
            background-color: #F8FBFF;
        }
        .mode-card h3 {
            margin-top: 0;
            font-size: 1.1em;
            display: flex;
            align-items: center;
            gap: 10px;
        }
        .mode-card p { font-size: 0.85em; color: var(--secondary-text); margin-bottom: 0; }
        .mode-card .icon-placeholder {
            font-size: 1.5em;
        }

        /* Model Controls Panel */
        #model-controls-panel {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 15px;
            padding: 20px;
            background-color: var(--surface-color);
            border-radius: 8px;
            box-shadow: var(--elevation-low);
            margin-bottom: 20px;
        }
        .control-group label { display: block; font-size: 0.85em; color: var(--secondary-text); margin-bottom: 5px; }
        .control-group input[type="number"], .control-group select {
            width: 100%;
            padding: 8px;
            border: 1px solid var(--border-color);
            border-radius: 4px;
            box-sizing: border-box;
            font-size: 0.9em;
            color: var(--text-color);
        }
        
        /* Dashboard */
        #model-dashboard {
            display: grid;
            grid-template-columns: 2fr 1fr;
            gap: 20px;
            margin-top: 30px;
        }
        #chart-container {
            background-color: var(--surface-color);
            padding: 20px;
            border-radius: 8px;
            box-shadow: var(--elevation-low);
        }
        #metrics-panel {
            background-color: var(--surface-color);
            padding: 20px;
            border-radius: 8px;
            box-shadow: var(--elevation-low);
            border-left: 4px solid var(--google-green);
        }
        #metrics-panel h3 { margin-top: 0; color: var(--google-green); font-weight: 500; font-size: 1.2em; }
        .metric-item { margin-bottom: 10px; font-size: 0.95em; }
        .metric-item strong { display: block; font-size: 1.1em; color: var(--text-color); }
        
        /* Data Analytics Dashboard */
        #data-analytics-dashboard {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
            margin-top: 20px;
        }
        .dashboard-card {
            background-color: var(--surface-color);
            padding: 20px;
            border-radius: 8px;
            box-shadow: var(--elevation-low);
        }
        .dashboard-card h3 { 
            margin-top: 0; 
            font-size: 1.2em; 
            color: var(--primary-blue);
        }
        /* Heatmap styles (omitted for brevity, assume correct styling) */

        /* Component Styles */
        /* ... existing styles for buttons, textareas, etc. ... */
        .training-status { background-color: #E8F0FE; border-left: 4px solid var(--primary-blue); padding: 12px 15px; border-radius: 4px; margin: 15px 0; font-size: 0.9em; display: none; }
        .training-status.active { display: block; animation: pulse 2s infinite; }
        @keyframes pulse { 0%, 100% { opacity: 1; } 50% { opacity: 0.8; } }
        .aws-config-modal { position: fixed; top: 0; left: 0; width: 100%; height: 100%; background: rgba(0,0,0,0.6); display: none; justify-content: center; align-items: center; z-index: 2000; }
        .aws-config-content { background: white; padding: 30px; border-radius: 12px; box-shadow: 0 4px 20px rgba(0,0,0,0.3); max-width: 500px; width: 90%; }
        /* ... styles for file preview, progress bars, etc. ... */
    </style>
</head>
<body onload="initializeApp()">
<div class="top-header">
    <i class="fas fa-bars" style="margin-right: 20px; font-size: 1.2em;"></i>
    <h1><i class="fas fa-brain"></i> DIY LLM Toolkit</h1>
    </div>
<div class="main-content-area">
    <div class="side-nav">
        <div class="nav-item active"> <i class="fas fa-database"></i> Data & Training </div>
        </div>
    <div class="content-wrapper">
        <p style="font-size: 0.95em; margin-bottom: 25px;">A modular prototype for training lightweight LLMs, supporting Markov chain fallback and TensorFlow-based attention simulation.</p>
        
        <section id="training-mode-selection">
            <h2>Training Mode Selection</h2>
            <div class="mode-selector">
                <div class="mode-card selected" id="mode-local" onclick="setModelMode('LOCAL')">
                    <h3><i class="fas fa-laptop-code icon-placeholder" style="color: var(--primary-blue);"></i> Local (TF.js)</h3>
                    <p>Fast client-side training using your device's resources. Ideal for prototyping and small data.</p>
                </div>
                <div class="mode-card" id="mode-worker" onclick="setModelMode('WORKER')">
                    <h3><i class="fas fa-sync-alt icon-placeholder" style="color: var(--google-orange);"></i> Worker (Persistent)</h3>
                    <p>Background training with Web Workers and IndexedDB checkpoints. Non-blocking UI and resumable.</p>
                </div>
                <div class="mode-card" id="mode-cloud" onclick="setModelMode('CLOUD')">
                    <h3><i class="fab fa-aws icon-placeholder" style="color: #FF9900;"></i> Cloud (SageMaker)</h3>
                    <p>High-performance GPU training orchestrated via an AWS backend. Required for large, terabyte-scale data.</p>
                </div>
            </div>
            <div class="training-status" id="training-status">
                <i class="fas fa-spinner fa-spin"></i> Training in progress... <span id="training-progress-text">Epoch 0/0</span>
            </div>
        </section>

        <section id="data-ingestion-section">
            <h2>Data Ingestion & Tokenization</h2>
            <div class="data-source-tabs">
                <div class="data-source-card" onclick="showAwsConfigModal()">
                    <h3>AWS S3 Storage</h3>
                    <i class="fab fa-aws" style="color: #FF9900; font-size: 2.5em; margin-bottom: 16px;"></i>
                    <p style="font-size: 0.9em; font-weight: 500;">Connect to an AWS S3 bucket to stream training data.</p>
                    <button style="background-color: #FF9900;" onclick="event.stopPropagation(); showAwsConfigModal();"><i class="fas fa-link"></i> Connect S3 Bucket</button>
                </div>
                <div class="data-source-card">
                    <h3>Sample Dataset</h3>
                    <i class="fas fa-book" style="color: #9334E9; font-size: 2.5em; margin-bottom: 16px;"></i>
                    <p style="font-size: 0.9em;">Load a sample text corpus for quick testing.</p>
                    <button onclick="loadSampleData()" style="background-color: #9334E9;"><i class="fas fa-file-alt"></i> Load Sample Text</button>
                </div>
                </div>
            <div style="display: flex; gap: 15px; justify-content: flex-start; margin-bottom: 30px;">
                <button onclick="dataHandler.tokenizeAndBuildMatrix()"><i class="fas fa-list-ol"></i> Tokenize & Preprocess</button>
                <button onclick="handleTrainButtonClick()" id="train-button" style="background-color: #3C769D;"><i class="fas fa-bolt"></i> Train Model</button>
            </div>
        </section>
        
        <hr class="divider">
        
        <section id="model-section">
            <h2>Model Configuration & Execution</h2>
            <div id="model-dashboard">
                <div id="chart-container">
                    <h3><i class="fas fa-chart-area"></i> Live Loss Curve</h3>
                    <canvas id="lossChart"></canvas>
                </div>
                <div id="metrics-panel">
                    <h3><i class="fas fa-tachometer-alt"></i> Model Metrics</h3>
                    <div class="metric-item">Mode: <strong id="metric-mode">LOCAL</strong></div>
                    <button onclick="miniTransformer.saveModel()" style="margin-top: 15px;"><i class="fas fa-save"></i> Save Model Weights</button>
                    <button onclick="miniTransformer.loadModel()" style="margin-top: 10px; background-color: #5F6368;"><i class="fas fa-file-upload"></i> Load Model Weights</button>
                </div>
            </div>
        </section>
        
        <hr class="divider">
        
        <section id="generation-section">
            <h2>Text Generation</h2>
            <div id="llm-output">
                <em>Generated text will appear here. Start by tokenizing and training your model.</em>
            </div>
        </section>
    </div>
</div>

<div id="aws-config-modal" class="aws-config-modal">
    <div class="aws-config-content">
        <h3><i class="fab fa-aws"></i> AWS Configuration</h3>
        <p style="font-size: 0.9em; color: var(--secondary-text);">Select your action and enter credentials. For Cloud Training, this will call your deployed AWS Lambda/API Gateway endpoint.</p>

        <label for="aws-action">Action</label>
        <select id="aws-action">
            <option value="S3_DOWNLOAD">Download Data from S3 (Client-side)</option>
            <option value="SAGEMAKER_TRAIN">Start Cloud Training (Server-side API)</option>
        </select>

        <label for="aws-api-endpoint">Cloud Training API Endpoint (URL)</label>
        <input type="text" id="aws-api-endpoint" placeholder="https://xxxxxxxx.execute-api.us-east-1.amazonaws.com/prod/train">
        
        <div style="display: flex; gap: 10px; margin-top: 20px; justify-content: flex-end;">
            <button onclick="closeAwsConfigModal()" style="background-color: #5F6368;">Cancel</button>
            <button onclick="handleAwsAction()" style="background-color: #FF9900;"><i class="fas fa-cloud-upload-alt"></i> Execute Action</button>
        </div>
    </div>
</div>

<script>
    // =========================================================================
    // GLOBAL CONFIGURATION & STATE
    // =========================================================================
    const CONFIG = {
        modelMode: 'LOCAL',
        maxTokens: 50,
        temperature: 0.7,
        embeddingDim: 128,
        numHeads: 4,
        ffnDim: 256,
        train: {
            epochs: 20,
            batchSize: 16,
            learningRate: 0.0005
        },
        workerFile: 'training-worker.js',
        cloudApiEndpoint: '', // Populated from UI input
        SEQUENCE_LENGTH: 10,
        UNK_TOKEN_ID: 0,
        MAX_CHECKPOINT_SIZE_MB: 50,
        DB_NAME: 'LLMTrainingDB',
        STORE_NAME: 'Checkpoints'
    };
    
    let lossChart = null;
    let tokenChart = null;
    let worker = null;
    let currentTrainingAbortController = null;

    const state = new Proxy({
        mode: CONFIG.modelMode,
        vocabSize: 0,
        currentLoss: 'N/A',
        epochsRun: 0,
        latency: 'N/A',
        memoryUsage: '0 MB',
        isTraining: false,
        isTokenized: false,
        textCorpus: ""
    }, {
        set(obj, prop, value) {
            obj[prop] = value;
            updateUI(prop, value);
            return true;
        }
    });

    // =========================================================================
    // UI & UTILITY FUNCTIONS
    // =========================================================================
    function showAlert(message, title = 'Notification', type = 'info') {
        // ... (Implementation for custom alert) ...
    }
    
    function initializeLossChart() {
        // ... (Implementation for Chart.js Loss Chart) ...
    }
    
    function initializeTokenChart() {
        // ... (Implementation for Chart.js Token Chart) ...
    }

    function setModelMode(mode) {
        if (state.isTraining) {
            showAlert("Cannot switch modes while training is active.", "Training Locked", 'error');
            return;
        }
        state.mode = mode;
        document.querySelectorAll('.mode-card').forEach(card => card.classList.remove('selected'));
        document.getElementById(`mode-${mode.toLowerCase()}`).classList.add('selected');
        document.getElementById('metric-mode').textContent = mode;
        
        if (mode === 'WORKER') {
            initializeWorker();
            checkWorkerCheckpoint(); // Check for resumable progress
        } else if (worker) {
            worker.terminate();
            worker = null;
        }

        // Show a prompt if switching to Cloud without an endpoint
        if (mode === 'CLOUD' && !CONFIG.cloudApiEndpoint) {
            showAlert("You are in Cloud Mode. Please configure your AWS API Endpoint via the 'Connect S3 Bucket' modal to start remote training.", "Cloud Mode Activated", 'warning');
        }
    }

    function updateUI(prop, value) {
        switch (prop) {
            case 'mode':
                document.getElementById('metric-mode').textContent = value;
                break;
            case 'vocabSize':
                document.getElementById('metric-vocab-size').textContent = value.toLocaleString();
                break;
            case 'currentLoss':
                document.getElementById('metric-loss').textContent = typeof value === 'number' ? value.toFixed(4) : value;
                break;
            case 'epochsRun':
                document.getElementById('metric-epochs').textContent = value.toLocaleString();
                break;
            case 'latency':
                document.getElementById('metric-latency').textContent = value;
                break;
            case 'memoryUsage':
                document.getElementById('metric-memory').textContent = value;
                break;
            case 'isTraining':
                const trainButton = document.getElementById('train-button');
                const statusElement = document.getElementById('training-status');
                trainButton.disabled = value;
                trainButton.textContent = value ? 'Stop Training' : 'Train Model';
                trainButton.onclick = value ? cancelTraining : handleTrainButtonClick;
                statusElement.classList.toggle('active', value);
                break;
            case 'isTokenized':
                document.getElementById('train-button').disabled = !value;
                break;
        }
    }

    function initializeApp() {
        initializeLossChart();
        initializeTokenChart();
        setModelMode(CONFIG.modelMode);
        // Add event listeners for drag and drop, etc.
        // ...
    }

    // =========================================================================
    // AWS S3 & CLOUD ORCHESTRATION
    // =========================================================================
    function showAwsConfigModal() {
        document.getElementById('aws-config-modal').style.display = 'flex';
    }

    function closeAwsConfigModal() {
        document.getElementById('aws-config-modal').style.display = 'none';
    }

    function handleAwsAction() {
        const action = document.getElementById('aws-action').value;
        const region = document.getElementById('aws-region').value;
        const accessKeyId = document.getElementById('aws-access-key').value;
        const secretAccessKey = document.getElementById('aws-secret-key').value;
        const bucket = document.getElementById('aws-bucket').value;
        const prefix = document.getElementById('aws-prefix').value;
        const apiEndpoint = document.getElementById('aws-api-endpoint').value;

        if (action === 'S3_DOWNLOAD') {
            // Client-side S3 Download
            if (!region || !accessKeyId || !secretAccessKey || !bucket) {
                showAlert("Please fill in all S3 required fields.", "Missing Credentials", 'error');
                return;
            }
            // Temporarily configure AWS SDK (NOTE: Not secure for production)
            AWS.config.update({
                region: region,
                credentials: new AWS.Credentials(accessKeyId, secretAccessKey)
            });
            dataHandler.streamS3Data(bucket, prefix);
        } else if (action === 'SAGEMAKER_TRAIN') {
            // Server-side Cloud Training Orchestration
            if (!apiEndpoint) {
                showAlert("Please enter the Cloud Training API Endpoint URL.", "Missing Endpoint", 'error');
                return;
            }
            CONFIG.cloudApiEndpoint = apiEndpoint;
            startCloudTraining(region, bucket, prefix);
        }
        closeAwsConfigModal();
    }

    function startCloudTraining(region, bucket, prefix) {
        if (!state.isTokenized) {
            showAlert("Please tokenize your data first.", "Pre-requisite Missing", 'warning');
            return;
        }

        // Simulates the API call to your AWS Lambda/FastAPI backend
        showAlert("Attempting to launch SageMaker training job via API...", "Cloud Training Launching", 'info');
        state.isTraining = true;

        fetch(CONFIG.cloudApiEndpoint, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                action: 'START_TRAINING',
                s3Config: { region, bucket, prefix },
                modelConfig: {
                    vocabSize: state.vocabSize,
                    embeddingDim: CONFIG.embeddingDim,
                    epochs: CONFIG.train.epochs,
                    learningRate: CONFIG.train.learningRate
                }
            })
        })
        .then(response => response.json())
        .then(data => {
            if (data.status === 'SUCCESS') {
                showAlert(`SageMaker Job Launched: ${data.jobId}. Status streaming starting...`, "Success!", 'success');
                // Start a WebSocket connection to stream metrics
                connectToCloudWebSocket(data.websocketUrl || 'ws://mock-cloud-metrics.com'); 
            } else {
                showAlert(`Cloud Launch Failed: ${data.message}`, "API Error", 'error');
                state.isTraining = false;
            }
        })
        .catch(error => {
            showAlert(`Network or CORS Error: Could not connect to API endpoint. ${error.message}`, "Network Error", 'error');
            state.isTraining = false;
        });
    }

    let cloudWs = null;
    function connectToCloudWebSocket(url) {
        if (cloudWs) cloudWs.close();
        cloudWs = new WebSocket(url);

        cloudWs.onopen = () => {
            console.log("Connected to Cloud Metrics Stream.");
            document.getElementById('training-progress-text').textContent = "Connected to Cloud Stream. Awaiting metrics...";
        };

        cloudWs.onmessage = (event) => {
            try {
                const metric = JSON.parse(event.data);
                if (metric.type === 'progress') {
                    document.getElementById('training-progress-text').textContent = 
                        `Cloud: Epoch ${metric.epoch}/${metric.totalEpochs} - Batch ${metric.step}/${metric.totalSteps}`;
                } else if (metric.type === 'loss') {
                    updateLossChart(metric.epoch, metric.loss);
                    state.currentLoss = metric.loss;
                    state.epochsRun = metric.epoch;
                } else if (metric.type === 'complete') {
                    showAlert("Cloud Training Completed!", "Job Finished", 'success');
                    state.isTraining = false;
                    cloudWs.close();
                }
            } catch (e) {
                console.error("Failed to parse cloud metric:", event.data);
            }
        };

        cloudWs.onclose = () => {
            console.log("Cloud Metrics Stream closed.");
            if (state.isTraining) {
                showAlert("Cloud metrics stream closed. Check your AWS job status.", "Stream Disconnected", 'warning');
            }
        };

        cloudWs.onerror = (error) => {
            console.error("WebSocket Error:", error);
            showAlert("Cloud Stream Error. Disconnecting.", "WebSocket Error", 'error');
            state.isTraining = false;
        };
    }

    // =========================================================================
    // TRAINING ORCHESTRATION (Local, Worker, Cloud)
    // =========================================================================
    function handleTrainButtonClick() {
        if (state.isTraining) {
            cancelTraining();
            return;
        }

        if (!state.isTokenized) {
            showAlert("Please tokenize your data first.", "Pre-requisite Missing", 'warning');
            return;
        }

        if (state.mode === 'LOCAL') {
            miniTransformer.trainOnText(state.textCorpus);
        } else if (state.mode === 'WORKER') {
            startWorkerTraining();
        } else if (state.mode === 'CLOUD') {
            // This relies on the user configuring the Cloud API Endpoint in the modal
            if (CONFIG.cloudApiEndpoint) {
                // Call the mock function to simulate server-side launch and WebSocket connect
                startCloudTraining("us-east-1", "your-bucket", "data/"); 
            } else {
                showAlert("Cloud Mode requires setting up the API Endpoint via the AWS Config Modal.", "Configuration Required", 'warning');
                showAwsConfigModal();
            }
        }
    }

    function cancelTraining() {
        if (state.mode === 'LOCAL') {
            if (currentTrainingAbortController) {
                currentTrainingAbortController.abort();
            }
        } else if (state.mode === 'WORKER') {
            if (worker) {
                worker.postMessage({ command: 'STOP' });
                showAlert("Worker training has been requested to stop.", "Stopping Worker", 'info');
            }
        } else if (state.mode === 'CLOUD') {
            if (cloudWs) cloudWs.close();
            // In a real app, you'd send a DELETE request to your API to stop the SageMaker job
            showAlert("Cloud training stopped locally. You must manually stop the SageMaker job in your AWS console.", "Cloud Stop", 'warning');
        }
        state.isTraining = false;
    }

    // =========================================================================
    // WEB WORKER LOGIC (For 'WORKER' Mode)
    // =========================================================================
    function initializeWorker() {
        if (worker) worker.terminate();
        try {
            worker = new Worker(CONFIG.workerFile);
            worker.onmessage = handleWorkerMessage;
            worker.onerror = handleWorkerError;
            console.log("Worker initialized.");
        } catch (e) {
            showAlert(`Failed to initialize Web Worker. Make sure ${CONFIG.workerFile} is in the same directory.`, "Worker Error", 'error');
        }
    }

    function handleWorkerMessage(event) {
        const data = event.data;
        switch (data.command) {
            case 'READY':
                console.log("Worker is ready.");
                break;
            case 'PROGRESS':
                document.getElementById('training-progress-text').textContent = 
                    `Worker: Epoch ${data.epoch}/${CONFIG.train.epochs} - Batch ${data.step}/${data.totalSteps}`;
                updateLossChart(data.epoch, data.loss);
                state.currentLoss = data.loss;
                state.epochsRun = data.epoch;
                state.memoryUsage = `${(data.memory / 1024 / 1024).toFixed(2)} MB`;
                break;
            case 'COMPLETE':
                showAlert("Worker training complete!", "Success", 'success');
                state.isTraining = false;
                break;
            case 'ERROR':
                showAlert(`Worker Error: ${data.message}`, "Training Failed", 'error');
                state.isTraining = false;
                break;
            case 'CHECKPOINT_FOUND':
                // Prompt user to resume
                const resume = confirm(`Progress found! Resume training from Epoch ${data.epoch} with Loss ${data.loss.toFixed(4)}?`);
                if (resume) {
                    startWorkerTraining({ resume: true, checkpointId: data.checkpointId });
                } else {
                    worker.postMessage({ command: 'DELETE_CHECKPOINT', checkpointId: data.checkpointId });
                }
                break;
            case 'QUOTA_ERROR':
                showAlert(`Storage Quota Reached: Cannot save checkpoint. Please free up space or download the current model.`, "Storage Error", 'error');
                // You would implement a model download function here
                state.isTraining = false;
                break;
        }
    }

    function handleWorkerError(event) {
        showAlert(`Unhandled Worker Exception: ${event.message}`, "Fatal Worker Error", 'error');
        state.isTraining = false;
        event.preventDefault();
    }

    function checkWorkerCheckpoint() {
        if (worker) {
            worker.postMessage({ command: 'CHECK_CHECKPOINT' });
        }
    }

    function startWorkerTraining(options = {}) {
        if (!worker) initializeWorker();

        state.isTraining = true;
        const trainData = {
            command: 'START',
            corpus: state.textCorpus,
            vocab: tokenizer.getVocabulary(), // Assumes tokenizer object exists
            config: CONFIG,
            resume: options.resume || false,
            checkpointId: options.checkpointId
        };
        worker.postMessage(trainData);
        showAlert("Worker training started in the background. UI is non-blocking.", "Training Started", 'info');
    }

    // =========================================================================
    // TOKENIZER (Simplified Client-side Model)
    // =========================================================================
    const tokenizer = {
        vocab: new Map(),
        idToToken: new Map(),

        tokenize(text) {
            // Simple tokenization: split by space, normalize, filter
            const tokens = text.toLowerCase().match(/\b\w+\b/g) || [];
            
            // Build vocabulary if not built
            if (this.vocab.size === 0) {
                this.buildVocabulary(tokens);
            }

            // Map tokens to IDs
            return tokens.map(token => this.vocab.get(token) || CONFIG.UNK_TOKEN_ID);
        },

        buildVocabulary(tokens) {
            // Reserve 0 for UNK and 1 for PAD
            let currentId = 2;
            this.vocab.set('[UNK]', CONFIG.UNK_TOKEN_ID);
            this.idToToken.set(CONFIG.UNK_TOKEN_ID, '[UNK]');
            this.vocab.set('[PAD]', 1);
            this.idToToken.set(1, '[PAD]');

            const counts = {};
            tokens.forEach(token => {
                counts[token] = (counts[token] || 0) + 1;
            });

            // Sort by frequency and assign IDs
            Object.keys(counts).sort((a, b) => counts[b] - counts[a]).forEach(token => {
                if (!this.vocab.has(token)) {
                    this.vocab.set(token, currentId);
                    this.idToToken.set(currentId, token);
                    currentId++;
                }
            });

            state.vocabSize = this.vocab.size;
            state.isTokenized = true;
            // Update token frequency chart and heatmap here
            // ...
        },

        getToken(id) {
            return this.idToToken.get(id) || '[UNK]';
        },

        getVocabulary() {
            return {
                vocab: Array.from(this.vocab.entries()),
                idToToken: Array.from(this.idToToken.entries())
            };
        }
    };

    const dataHandler = {
        tokenizeAndBuildMatrix() {
            const text = document.getElementById('text-input').value || state.textCorpus;
            if (!text) {
                showAlert("Please enter or load a text corpus first.", "No Data", 'warning');
                return;
            }
            state.textCorpus = text;
            tokenizer.buildVocabulary(tokenizer.tokenize(text));
            showAlert(`Tokenization complete! Vocabulary size: ${state.vocabSize}`, "Success", 'success');
        },

        streamS3Data(bucket, prefix) {
            // Real S3 streaming logic using AWS SDK
            const s3 = new AWS.S3();
            const params = { Bucket: bucket, Prefix: prefix };

            showAlert("Listing files in S3 bucket. This may take a moment...", "Connecting S3", 'info');
            state.textCorpus = ""; // Clear existing corpus

            s3.listObjectsV2(params, (err, data) => {
                if (err) {
                    showAlert(`S3 List Error: ${err.message}. Check credentials.`, "AWS Error", 'error');
                    return;
                }

                const textFiles = data.Contents.filter(item => 
                    item.Key.endsWith('.txt') || item.Key.endsWith('.csv') || item.Key.endsWith('.md')
                );

                if (textFiles.length === 0) {
                    showAlert("No .txt, .csv, or .md files found in this location.", "No Files Found", 'warning');
                    return;
                }

                // Sequential download and concatenation (simplified)
                const downloadPromises = textFiles.map(file => {
                    return new Promise((resolve, reject) => {
                        s3.getObject({ Bucket: bucket, Key: file.Key }, (downloadErr, downloadData) => {
                            if (downloadErr) return reject(downloadErr);
                            resolve(downloadData.Body.toString('utf-8'));
                        });
                    });
                });

                Promise.all(downloadPromises)
                    .then(corpusParts => {
                        state.textCorpus = corpusParts.join('\n');
                        document.getElementById('text-input').value = state.textCorpus;
                        showAlert(`Successfully downloaded ${textFiles.length} files (${(state.textCorpus.length / 1024 / 1024).toFixed(2)} MB). Ready for tokenization.`, "S3 Download Complete", 'success');
                        dataHandler.tokenizeAndBuildMatrix(); // Auto-tokenize after download
                    })
                    .catch(downloadErr => {
                        showAlert(`S3 Download Error: ${downloadErr.message}`, "Download Failed", 'error');
                    });
            });
        }
    };

    function loadSampleData() {
        // High-quality sample text about ML (no HTML tokens!)
        const sampleText = `Machine learning is a subset of artificial intelligence that enables computers to learn from data without being explicitly programmed. It focuses on the development of programs that can access data and use it to learn for themselves. The process starts with feeding the algorithm high-quality data and then training the model to make predictions or decisions. Deep learning, a specialized field within machine learning, involves neural networks with multiple layers (hence "deep") to analyze data. A key architecture, the Transformer model, introduced the attention mechanism, allowing the model to weigh the importance of different parts of the input data when making a prediction. This innovation revolutionized Natural Language Processing (NLP) and is the foundation for large language models (LLMs) like GPT and BERT. Training these models is computationally expensive, often requiring powerful GPUs or TPUs running on cloud services like AWS SageMaker or Google Cloud's Vertex AI.`;
        document.getElementById('text-input').value = sampleText;
        state.textCorpus = sampleText;
        showAlert("Sample text loaded successfully! Ready for tokenization.", "Data Loaded", 'success');
    }

    // =========================================================================
    // TRANSFORMER MODEL (Simplified Client-side Model - tf.js)
    // This is a minimal implementation to show the architecture and training loop
    // =========================================================================
    const miniTransformer = {
        model: null,
        
        createModel(vocabSize, embeddingDim, sequenceLength) {
            // Simplified Attention/FFN block
            const attentionBlock = (input, heads, ffnDim) => {
                const headSize = embeddingDim / heads;
                
                let att = tf.layers.multiHeadAttention({ 
                    numHeads: heads, 
                    keyDim: headSize 
                }).apply([input, input, input]);
                
                att = tf.layers.dropout({ rate: 0.2 }).apply(att);
                att = tf.layers.layerNormalization({ epsilon: 1e-6 }).apply(tf.layers.add().apply([input, att]));
                
                let ffn = tf.layers.dense({ units: ffnDim, activation: 'relu' }).apply(att);
                ffn = tf.layers.dense({ units: embeddingDim }).apply(ffn);
                ffn = tf.layers.dropout({ rate: 0.2 }).apply(ffn);
                return tf.layers.layerNormalization({ epsilon: 1e-6 }).apply(tf.layers.add().apply([att, ffn]));
            };

            const input = tf.input({ shape: [sequenceLength] });
            let embedding = tf.layers.embedding({ 
                inputDim: vocabSize, 
                outputDim: embeddingDim, 
                embeddingsRegularizer: tf.regularizers.l2({ l2: 1e-5 })
            }).apply(input);

            // Add position embedding (simplified by adding a trainable constant)
            const posEmbedding = tf.layers.embedding({
                inputDim: sequenceLength,
                outputDim: embeddingDim,
                trainable: true 
            }).apply(tf.range(0, sequenceLength).expandDims(0).tile([tf.shape(embedding).arraySync()[0], 1]));
            embedding = tf.layers.add().apply([embedding, posEmbedding]);

            // Add four attention blocks (for better context)
            let output = attentionBlock(embedding, CONFIG.numHeads, CONFIG.ffnDim);
            output = attentionBlock(output, CONFIG.numHeads, CONFIG.ffnDim);
            output = attentionBlock(output, CONFIG.numHeads, CONFIG.ffnDim);
            output = attentionBlock(output, CONFIG.numHeads, CONFIG.ffnDim);

            // Flatten and output layer
            output = tf.layers.flatten().apply(output);
            output = tf.layers.dense({ units: vocabSize, activation: 'softmax' }).apply(output);

            this.model = tf.model({ inputs: input, outputs: output });

            this.model.compile({
                optimizer: tf.train.adam(CONFIG.train.learningRate),
                loss: 'categoricalCrossentropy',
                metrics: ['accuracy']
            });

            console.log("MiniTransformer Model Created.");
            document.getElementById('metric-memory').textContent = `${(tf.memory().numBytes / 1024 / 1024).toFixed(2)} MB`;
        },

        async trainOnText(corpus) {
            if (!this.model) {
                this.createModel(state.vocabSize, CONFIG.embeddingDim, CONFIG.SEQUENCE_LENGTH);
            }

            state.isTraining = true;
            const tokenIds = tokenizer.tokenize(corpus);
            const vocabSize = state.vocabSize;
            const seqLen = CONFIG.SEQUENCE_LENGTH;
            const { epochs, batchSize } = CONFIG.train;

            // Prepare sequential data (X: sequence, Y: next token)
            const xs = [];
            const ys = [];
            for (let i = 0; i < tokenIds.length - seqLen; i++) {
                xs.push(tokenIds.slice(i, i + seqLen));
                ys.push(tokenIds[i + seqLen]);
            }
            
            const numSamples = xs.length;
            if (numSamples === 0) {
                showAlert("Not enough data to form sequences. Need more text.", "Data Shortage", 'error');
                state.isTraining = false;
                return;
            }

            // Convert to Tensors
            const xTrain = tf.tensor2d(xs, [numSamples, seqLen]);
            // Convert next token ID to one-hot encoding for categoricalCrossentropy loss
            const yTrain = tf.oneHot(tf.tensor1d(ys, 'int32'), vocabSize); 

            currentTrainingAbortController = new AbortController();

            const onBatchEnd = async (batch, logs) => {
                if (currentTrainingAbortController.signal.aborted) {
                    this.model.stopTraining = true;
                }
                document.getElementById('training-progress-text').textContent = 
                    `Epoch ${state.epochsRun}/${epochs} - Batch ${batch + 1}/${Math.ceil(numSamples / batchSize)}`;
                state.memoryUsage = `${(tf.memory().numBytes / 1024 / 1024).toFixed(2)} MB`;
                // Wait for the next animation frame to prevent UI freezing
                await tf.nextFrame(); 
            };

            const onEpochEnd = (epoch, logs) => {
                updateLossChart(epoch + 1, logs.loss);
                state.currentLoss = logs.loss;
                state.epochsRun = epoch + 1;
                state.latency = `${(logs.elapsedTime / 1000).toFixed(2)}s/epoch`;
            };

            try {
                const startTime = performance.now();
                await this.model.fit(xTrain, yTrain, {
                    epochs: epochs,
                    batchSize: batchSize,
                    callbacks: { onBatchEnd, onEpochEnd }
                });
                const endTime = performance.now();
                state.isTraining = false;
                showAlert(`Training completed in ${((endTime - startTime) / 1000).toFixed(2)} seconds.`, "Training Success", 'success');

            } catch (e) {
                if (e.message === 'model.stopTraining is true.') {
                    showAlert("Training manually stopped.", "Interrupted", 'warning');
                } else {
                    showAlert(`Training failed: ${e.message}`, "TF.js Error", 'error');
                    console.error(e);
                }
                state.isTraining = false;
            } finally {
                xTrain.dispose();
                yTrain.dispose();
                currentTrainingAbortController = null;
            }
        },

        async generateText(prompt) {
            // ... (Implementation for text generation using the trained model) ...
            // This includes logic to handle UNK/PAD token suppression and temperature sampling
        },

        async saveModel() {
            // ... (Implementation for saving model weights locally) ...
        },

        async loadModel() {
            // ... (Implementation for loading model weights locally) ...
        }
    };

    // =========================================================================
    // INITIALIZATION AND MISC
    // =========================================================================
    // ... (All initialization is now done in initializeApp) ...
    
</script>
</body>
</html>
