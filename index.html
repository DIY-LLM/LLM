<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DIY LLM Toolkit | Modular Prototype</title>
    <!-- Inter Font (Google Font Equivalent in previous snippet was Roboto) -->
    <link href="https://fonts.googleapis.com/css?family=Inter:wght@300;400;500;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">
    <!-- TensorFlow.js for the Mini-Transformer -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.10.0/dist/tf.min.js"></script>
    <!-- Chart.js for data visualization -->
    <script src="https://cdn.jsdelivr.net/npm/chart.js@3.7.1/dist/chart.min.js"></script>
    
    <style>
        /* Google Cloud/Material Design Variables */
        :root {
            --primary-blue: #1A73E8;
            --header-blue: #1A2E44;
            --nav-panel-color: #F1F3F4;
            --active-item-color: #E8F0FE;
            --surface-color: #FFFFFF;
            --background-color: #F8F9FA;
            --text-color: #202124;
            --secondary-text: #5F6368;
            --border-color: #DADCE0;
            --google-red: #D93025;
            --google-green: #34A853;
            --google-yellow: #F9AB00;
            --shadow-smooth: 0 1px 3px 0 rgba(0, 0, 0, 0.1), 0 1px 2px 0 rgba(0, 0, 0, 0.06);
        }

        body {
            font-family: 'Inter', sans-serif;
            background-color: var(--background-color);
            color: var(--text-color);
            margin: 0;
            padding: 0;
            display: flex;
            height: 100vh;
            overflow: hidden;
        }

        /* Utility Classes */
        .card {
            background-color: var(--surface-color);
            border-radius: 8px;
            box-shadow: var(--shadow-smooth);
            padding: 20px;
            margin-bottom: 20px;
            border: 1px solid var(--border-color);
        }

        .button-primary {
            background-color: var(--primary-blue);
            color: white;
            padding: 10px 15px;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            transition: background-color 0.2s;
            font-weight: 500;
        }

        .button-primary:hover {
            background-color: #1669D9;
        }
        
        .button-secondary {
            background-color: var(--nav-panel-color);
            color: var(--text-color);
            padding: 10px 15px;
            border: 1px solid var(--border-color);
            border-radius: 4px;
            cursor: pointer;
            transition: background-color 0.2s;
            font-weight: 500;
        }

        .button-secondary:hover {
            background-color: #E6E9EB;
        }

        input[type="text"], textarea {
            width: 100%;
            padding: 10px;
            margin-top: 5px;
            border: 1px solid var(--border-color);
            border-radius: 4px;
            box-sizing: border-box;
            font-family: inherit;
        }

        /* Layout Structure */
        .sidebar {
            width: 250px;
            background-color: var(--nav-panel-color);
            padding: 20px 0;
            display: flex;
            flex-direction: column;
            border-right: 1px solid var(--border-color);
            flex-shrink: 0;
        }

        .header {
            color: var(--header-blue);
            font-size: 1.4em;
            font-weight: 700;
            padding: 0 20px 20px;
            border-bottom: 1px solid var(--border-color);
            margin-bottom: 10px;
        }

        .nav-item {
            display: flex;
            align-items: center;
            padding: 12px 20px;
            cursor: pointer;
            transition: background-color 0.2s;
            color: var(--secondary-text);
            font-weight: 500;
        }

        .nav-item i {
            margin-right: 12px;
            width: 20px;
            text-align: center;
        }

        .nav-item:hover:not(.active) {
            background-color: #EAECEF;
        }

        .nav-item.active {
            background-color: var(--active-item-color);
            color: var(--primary-blue);
            border-left: 3px solid var(--primary-blue);
            padding-left: 17px; /* Adjust padding for border */
        }

        .main-content-container {
            flex-grow: 1;
            padding: 30px;
            overflow-y: auto;
        }

        /* Responsive adjustments */
        @media (max-width: 768px) {
            body {
                flex-direction: column;
                height: auto;
                overflow-y: auto;
            }
            .sidebar {
                width: 100%;
                height: auto;
                padding: 10px 0;
                border-right: none;
                border-bottom: 1px solid var(--border-color);
            }
            .header {
                padding: 10px 20px;
                font-size: 1.2em;
            }
            .nav-item {
                padding: 10px 20px;
            }
            .main-content-container {
                padding: 15px;
            }
        }
    </style>
</head>
<body>

    <!-- Sidebar Navigation -->
    <div class="sidebar">
        <div class="header">
            DIY LLM Toolkit
        </div>
        <div class="nav-item active" data-tab-id="data-ingestion">
            <i class="fas fa-database"></i> Data Ingestion
        </div>
        <div class="nav-item" data-tab-id="model-training">
            <i class="fas fa-brain"></i> Model Training
        </div>
        <div class="nav-item" data-tab-id="text-generation">
            <i class="fas fa-keyboard"></i> Text Generation
        </div>
        <div class="nav-item" data-tab-id="analysis">
            <i class="fas fa-chart-line"></i> Analysis
        </div>
    </div>

    <!-- Main Content Area -->
    <div class="main-content-container" id="main-content">
        <!-- Content will be rendered here by JavaScript -->
        <div style="text-align: center; padding-top: 50px;">
            <i class="fas fa-arrow-left" style="font-size: 2em; color: var(--secondary-text); margin-bottom: 15px;"></i>
            <h2 style="color: var(--secondary-text);">Select a navigation item to begin.</h2>
        </div>
    </div>

    <script>
        // --- GLOBAL STATE MANAGEMENT ---
        const state = {
            activeTab: 'data-ingestion',
            corpus: "",
            corpusTokenCount: 0,
            vocabulary: new Set(),
            vocabSize: 0,
            markovModel: null,
            miniTransformer: null,
            mode: 'MARKOV', // MARKOV or TRANSFORMER
            isTraining: false,
        };

        const CONFIG = {
            markovOrder: 3,
            transformerEpochs: 10,
            transformerBatchSize: 64,
            transformerModelSize: 128,
            temperature: 0.7,
            maxGenerationLength: 500,
        };

        // --- AUTH/API PLACEHOLDERS ---
        const apiKey = ""; 

        // --- UTILITY FUNCTIONS ---

        // Simple debounce function
        const debounce = (func, delay) => {
            let timeout;
            return function(...args) {
                clearTimeout(timeout);
                timeout = setTimeout(() => func.apply(this, args), delay);
            };
        };
        
        // --- MARKOV MODEL IMPLEMENTATION ---
        class MarkovChain {
            constructor(order = 3) {
                this.order = order;
                this.chain = new Map();
                this.vocab = new Set();
            }

            // Simple text tokenization (words and punctuation)
            tokenize(text) {
                // Split by spaces, keep punctuation as separate tokens if surrounded by space
                return text.toLowerCase().match(/\S+/g) || [];
            }

            train(text) {
                const tokens = this.tokenize(text);
                if (tokens.length < this.order + 1) return;

                // Build vocabulary
                tokens.forEach(token => this.vocab.add(token));

                for (let i = 0; i <= tokens.length - this.order; i++) {
                    const state = tokens.slice(i, i + this.order).join(' ');
                    const nextToken = tokens[i + this.order];

                    if (!this.chain.has(state)) {
                        this.chain.set(state, new Map());
                    }

                    const nextTokens = this.chain.get(state);
                    nextTokens.set(nextToken, (nextTokens.get(nextToken) || 0) + 1);
                }
            }

            // Selects the next token based on weighted probability
            selectNext(nextTokens) {
                let totalWeight = 0;
                for (const count of nextTokens.values()) {
                    totalWeight += count;
                }

                let rand = Math.random() * totalWeight;

                for (const [token, count] of nextTokens.entries()) {
                    if (rand < count) {
                        return token;
                    }
                    rand -= count;
                }
                return null; // Fallback
            }

            generate(startPrompt, maxLength = CONFIG.maxGenerationLength) {
                if (!this.chain.size) return "Error: Markov model not trained.";

                const promptTokens = this.tokenize(startPrompt);
                let currentTokens = promptTokens.slice(-this.order);
                let resultTokens = [...promptTokens];

                for (let i = 0; i < maxLength; i++) {
                    const currentState = currentTokens.join(' ');
                    const nextTokens = this.chain.get(currentState);

                    if (!nextTokens) {
                        // Attempt to gracefully restart if the state is not found
                        if (this.chain.size > 0) {
                            const randomState = [...this.chain.keys()][Math.floor(Math.random() * this.chain.size)];
                            currentTokens = randomState.split(' ');
                            continue;
                        } else {
                            break; // Cannot continue generation
                        }
                    }

                    const nextToken = this.selectNext(nextTokens);
                    if (!nextToken) break;

                    resultTokens.push(nextToken);
                    currentTokens.shift();
                    currentTokens.push(nextToken);
                }
                
                // Join tokens back, being careful with punctuation (a simplification)
                return resultTokens.join(' ').replace(/\s([.,!?:;])/g, '$1');
            }
        }

        // --- MINI-TRANSFORMER IMPLEMENTATION (TF.js) ---
        class MiniTransformer {
            constructor(vocab, vocabSize) {
                this.vocab = [...vocab];
                this.vocabSize = vocabSize;
                this.stoi = new Map(this.vocab.map((token, i) => [token, i]));
                this.itos = this.vocab;
                this.model = null;
                this.inputSequenceLength = CONFIG.markovOrder; // Reusing the Markov order for initial sequence length
            }

            async buildModel() {
                if (this.model) {
                    this.model.dispose(); // Clean up old model if re-training
                }

                this.model = tf.sequential();
                
                // Input Embedding Layer
                this.model.add(tf.layers.embedding({
                    inputDim: this.vocabSize,
                    outputDim: CONFIG.transformerModelSize,
                    inputLength: this.inputSequenceLength,
                    name: 'embedding_layer'
                }));

                // Simple RNN/LSTM for sequential processing (a common proxy for simplified Transformer logic)
                this.model.add(tf.layers.lstm({
                    units: CONFIG.transformerModelSize * 2,
                    returnSequences: false,
                    name: 'lstm_layer'
                }));

                // Dense Layer for prediction (maps to vocabulary size)
                this.model.add(tf.layers.dense({
                    units: this.vocabSize,
                    activation: 'softmax',
                    name: 'output_layer'
                }));

                // Compile the model
                this.model.compile({
                    optimizer: tf.train.adam(),
                    loss: 'categoricalCrossentropy'
                });

                document.getElementById('training-status').innerHTML += `<p style="color: var(--google-green);"><i class="fas fa-check-circle"></i> Model Architecture Built.</p>`;
            }

            preprocess(text) {
                // Tokenization: Reuse Markov's simple tokenizer
                const markov = new MarkovChain();
                const tokens = markov.tokenize(text);
                
                // Generate sequences (X) and next tokens (Y)
                let X = [];
                let Y = [];

                for (let i = 0; i < tokens.length - this.inputSequenceLength; i++) {
                    const sequence = tokens.slice(i, i + this.inputSequenceLength);
                    const nextToken = tokens[i + this.inputSequenceLength];

                    // Convert tokens to indices
                    const x_indices = sequence.map(token => this.stoi.get(token));
                    const y_index = this.stoi.get(nextToken);

                    if (x_indices.every(idx => idx !== undefined) && y_index !== undefined) {
                        X.push(x_indices);
                        Y.push(y_index);
                    }
                }
                
                const xs = tf.tensor2d(X, [X.length, this.inputSequenceLength]);
                const ys = tf.oneHot(tf.tensor1d(Y, 'int32'), this.vocabSize);
                
                return { xs, ys };
            }

            async train(text) {
                document.getElementById('training-status').innerHTML = '<p><i class="fas fa-spinner fa-spin"></i> Preprocessing data...</p>';
                
                await this.buildModel();
                const { xs, ys } = this.preprocess(text);

                if (xs.shape[0] === 0) {
                    throw new Error("Corpus too small or failed to generate training sequences.");
                }

                document.getElementById('training-status').innerHTML += `<p style="color: var(--google-green);"><i class="fas fa-check-circle"></i> Data Prepared. Sequences: ${xs.shape[0]}</p>`;
                document.getElementById('training-status').innerHTML += `<p><i class="fas fa-spinner fa-spin"></i> Starting Training (${CONFIG.transformerEpochs} epochs)...</p>`;
                
                const history = await this.model.fit(xs, ys, {
                    epochs: CONFIG.transformerEpochs,
                    batchSize: CONFIG.transformerBatchSize,
                    shuffle: true,
                    callbacks: {
                        onEpochEnd: (epoch, logs) => {
                            document.getElementById('training-status').innerHTML = 
                                `<p><i class="fas fa-spinner fa-spin"></i> Training Epoch ${epoch + 1}/${CONFIG.transformerEpochs} | Loss: ${logs.loss.toFixed(4)}</p>`;
                        }
                    }
                });
                
                xs.dispose();
                ys.dispose();
                return history;
            }
            
            async generate(startPrompt, maxLength = CONFIG.maxGenerationLength) {
                if (!this.model) throw new Error("Mini-Transformer not trained. Please train the model first.");

                const markov = new MarkovChain();
                let resultTokens = markov.tokenize(startPrompt);
                let currentTokens = resultTokens.slice(-this.inputSequenceLength);

                if (currentTokens.length < this.inputSequenceLength) {
                    throw new Error(`Prompt must be at least ${this.inputSequenceLength} tokens long for Transformer generation.`);
                }
                
                // Using tf.tidy for memory management
                for (let i = 0; i < maxLength; i++) {
                    const nextToken = tf.tidy(() => {
                        // 1. Convert current tokens to index tensor
                        const x_indices = currentTokens.map(token => this.stoi.get(token)).filter(idx => idx !== undefined);
                        if (x_indices.length !== this.inputSequenceLength) return null; // stop if token not in vocab

                        const inputTensor = tf.tensor2d([x_indices], [1, this.inputSequenceLength]);

                        // 2. Predict probabilities (logits)
                        const prediction = this.model.predict(inputTensor); // Shape [1, vocabSize]
                        
                        // 3. Apply temperature and sample
                        const logits = tf.squeeze(prediction).div(tf.scalar(CONFIG.temperature));
                        const probabilities = tf.softmax(logits).arraySync();

                        // 4. Sample the next token index
                        let sampledIndex = -1;
                        let r = Math.random();
                        let cumulativeProbability = 0;
                        for (let j = 0; j < probabilities.length; j++) {
                            cumulativeProbability += probabilities[j];
                            if (r <= cumulativeProbability) {
                                sampledIndex = j;
                                break;
                            }
                        }

                        if (sampledIndex === -1) return null; // Should not happen

                        return this.itos[sampledIndex];
                    });

                    if (!nextToken) break;

                    resultTokens.push(nextToken);
                    currentTokens.shift();
                    currentTokens.push(nextToken);
                }

                // Join tokens back
                return resultTokens.join(' ').replace(/\s([.,!?:;])/g, '$1');
            }
        }

        // --- DATA INGESTION LOGIC ---

        function handleFileUpload(event) {
            const file = event.target.files[0];
            if (file) {
                const reader = new FileReader();
                reader.onload = (e) => {
                    const text = e.target.result;
                    processCorpus(text);
                };
                reader.readAsText(file);
            }
        }

        function handleTextPaste() {
            const textarea = document.getElementById('manual-text-input');
            const text = textarea.value;
            processCorpus(text);
        }

        function processCorpus(text) {
            state.corpus = text;
            
            // Re-initialize Markov to get fresh vocabulary
            const tempMarkov = new MarkovChain();
            tempMarkov.train(text); 
            
            state.vocabulary = tempMarkov.vocab;
            state.vocabSize = state.vocabulary.size;
            state.corpusTokenCount = tempMarkov.tokenize(text).length;

            updateIngestionStats();
            
            // Automatically switch to training tab after ingestion
            setActiveTab('model-training');
        }
        
        function updateIngestionStats() {
            const statsElement = document.getElementById('ingestion-stats');
            if (statsElement) {
                statsElement.innerHTML = `
                    <p><strong>Status:</strong> <span style="color: var(--google-green);">Corpus Loaded!</span></p>
                    <p><strong>Tokens:</strong> ${state.corpusTokenCount.toLocaleString()}</p>
                    <p><strong>Vocabulary Size:</strong> ${state.vocabSize.toLocaleString()}</p>
                    <p><strong>First 200 Chars:</strong> <em>${state.corpus.substring(0, 200).replace(/\n/g, ' ')}...</em></p>
                    <p style="margin-top: 15px;">You can now proceed to the **Model Training** tab.</p>
                `;
            }
        }

        // --- MODEL TRAINING LOGIC ---

        async function startTraining() {
            if (!state.corpus) {
                alert('Please ingest a text corpus first in the Data Ingestion tab.');
                return;
            }
            
            if (state.isTraining) return;
            state.isTraining = true;
            
            const mode = document.getElementById('model-mode').value;
            const statusElement = document.getElementById('training-status');
            const trainButton = document.getElementById('train-model-button');
            const settingsContainer = document.getElementById('training-settings');

            trainButton.disabled = true;
            trainButton.innerHTML = '<i class="fas fa-spinner fa-spin"></i> Training...';
            settingsContainer.style.opacity = 0.5;

            try {
                if (mode === 'MARKOV') {
                    statusElement.innerHTML = '<p><i class="fas fa-spinner fa-spin"></i> Training Markov Chain...</p>';
                    
                    state.markovModel = new MarkovChain(CONFIG.markovOrder);
                    state.markovModel.train(state.corpus);
                    
                    statusElement.innerHTML = `<p style="color: var(--google-green);">
                        <i class="fas fa-check-circle"></i> Markov Model (Order ${CONFIG.markovOrder}) Trained Successfully!
                    </p>`;
                    state.mode = 'MARKOV';
                } else { // TRANSFORMER
                    statusElement.innerHTML = '<p><i class="fas fa-spinner fa-spin"></i> Initializing Mini-Transformer (TF.js)...</p>';
                    
                    state.miniTransformer = new MiniTransformer(state.vocabulary, state.vocabSize);
                    const history = await state.miniTransformer.train(state.corpus);

                    statusElement.innerHTML = `<p style="color: var(--google-green);">
                        <i class="fas fa-check-circle"></i> Mini-Transformer Trained Successfully! Final Loss: ${history.history.loss.slice(-1)[0].toFixed(4)}
                    </p>`;
                    state.mode = 'TRANSFORMER';
                    renderLossChart(history);
                }
                
                document.getElementById('current-model-info').innerHTML = `
                    <p><strong>Current Active Model:</strong> <span style="color: var(--primary-blue);">${state.mode}</span></p>
                    <p><strong>Corpus Vocabulary:</strong> ${state.vocabSize.toLocaleString()}</p>
                    <p><strong>Ready for Generation!</strong></p>
                `;
                
                // Switch to generation tab on success
                setTimeout(() => setActiveTab('text-generation'), 1000);

            } catch (error) {
                statusElement.innerHTML = `<p style="color: var(--google-red);">
                    <i class="fas fa-exclamation-triangle"></i> Training Error: ${error.message}
                </p>`;
            } finally {
                state.isTraining = false;
                trainButton.disabled = false;
                trainButton.innerHTML = 'Start Training';
                settingsContainer.style.opacity = 1;
            }
        }
        
        let lossChartInstance = null;
        function renderLossChart(history) {
            const ctx = document.getElementById('loss-chart').getContext('2d');
            if (lossChartInstance) {
                lossChartInstance.destroy();
            }

            lossChartInstance = new Chart(ctx, {
                type: 'line',
                data: {
                    labels: history.history.loss.map((_, i) => `Epoch ${i + 1}`),
                    datasets: [{
                        label: 'Training Loss',
                        data: history.history.loss,
                        borderColor: varToColor('--primary-blue'),
                        backgroundColor: 'rgba(26, 115, 232, 0.2)',
                        tension: 0.1
                    }]
                },
                options: {
                    responsive: true,
                    scales: {
                        y: { beginAtZero: true, title: { display: true, text: 'Loss' } },
                        x: { title: { display: true, text: 'Epoch' } }
                    },
                    plugins: { legend: { display: false } }
                }
            });
        }
        
        function varToColor(variable) {
            return getComputedStyle(document.documentElement).getPropertyValue(variable).trim();
        }

        // --- TEXT GENERATION LOGIC ---

        async function startGeneration() {
            const promptElement = document.getElementById('generation-prompt');
            const prompt = promptElement.value.trim();
            const outputElement = document.getElementById('generation-output');
            
            if (!prompt) {
                outputElement.innerHTML = `<em style="color: var(--google-red);">Please enter a starting prompt.</em>`;
                return;
            }
            
            if (state.mode === 'MARKOV' && !state.markovModel) {
                 outputElement.innerHTML = `<em style="color: var(--google-red);">Please train the Markov Model first.</em>`;
                 return;
            }

            if (state.mode === 'TRANSFORMER' && !state.miniTransformer) {
                 outputElement.innerHTML = `<em style="color: var(--google-red);">Please train the Mini-Transformer first.</em>`;
                 return;
            }

            outputElement.innerHTML = '<div style="text-align: center; padding: 20px;"><i class="fas fa-spinner fa-spin" style="font-size: 2em; color: var(--primary-blue);"></i><br><br><em>Generating text...</em></div>';

            try {
                let generatedText = "";
                const startTime = performance.now();
                
                if (state.mode === 'MARKOV') {
                    generatedText = state.markovModel.generate(prompt);
                } else {
                    generatedText = await state.miniTransformer.generate(prompt);
                }

                const totalTime = ((performance.now() - startTime) / 1000).toFixed(2);
                
                outputElement.innerHTML = `
                    <div style="background-color: #E8F0FE; padding: 12px; border-radius: 6px; margin-bottom: 15px; border-left: 4px solid var(--primary-blue);">
                        <strong style="color: var(--primary-blue);">Prompt:</strong> ${prompt}<br>
                        <small style="color: var(--secondary-text);">Mode: ${state.mode} | Generation Time: ${totalTime}s | Temperature: ${CONFIG.temperature}</small>
                    </div>
                    <div style="line-height: 1.8; color: var(--text-color);">
                        ${generatedText.replace(/\n/g, '<br>')}
                    </div>
                `;
            } catch (error) {
                outputElement.innerHTML = `<em style="color: var(--google-red);">⚠ Error generating text: ${error.message}</em>`;
            }
        }
        
        // --- ANALYSIS LOGIC ---
        let analysisChartInstance = null;

        function runAnalysis() {
            if (!state.corpus) {
                document.getElementById('analysis-output').innerHTML = '<p style="color: var(--google-red);"><i class="fas fa-exclamation-triangle"></i> Please ingest a text corpus first in the Data Ingestion tab.</p>';
                return;
            }

            const markov = new MarkovChain();
            const tokens = markov.tokenize(state.corpus);
            
            // 1. Calculate Token Frequency
            const frequencyMap = {};
            tokens.forEach(token => {
                frequencyMap[token] = (frequencyMap[token] || 0) + 1;
            });

            // 2. Get Top 10 Tokens
            const sortedTokens = Object.entries(frequencyMap).sort(([, a], [, b]) => b - a);
            const top10 = sortedTokens.slice(0, 10);

            // 3. Render Chart
            renderAnalysisChart(top10);

            // 4. Update Summary
            document.getElementById('analysis-summary').innerHTML = `
                <div class="card">
                    <h3 style="color: var(--primary-blue);">Corpus Statistics</h3>
                    <p><strong>Total Tokens:</strong> ${tokens.length.toLocaleString()}</p>
                    <p><strong>Unique Vocabulary Size:</strong> ${state.vocabSize.toLocaleString()}</p>
                    <p><strong>Top 10 Most Frequent Tokens:</strong></p>
                    <ol>
                        ${top10.map(([token, count]) => `<li>'${token}' (${count})</li>`).join('')}
                    </ol>
                </div>
            `;
        }
        
        function renderAnalysisChart(topTokens) {
            const ctx = document.getElementById('analysis-chart').getContext('2d');
            if (analysisChartInstance) {
                analysisChartInstance.destroy();
            }
            
            const labels = topTokens.map(([token]) => token);
            const data = topTokens.map(([, count]) => count);

            analysisChartInstance = new Chart(ctx, {
                type: 'bar',
                data: {
                    labels: labels,
                    datasets: [{
                        label: 'Token Count',
                        data: data,
                        backgroundColor: varToColor('--primary-blue'),
                        borderColor: varToColor('--primary-blue'),
                        borderWidth: 1
                    }]
                },
                options: {
                    responsive: true,
                    scales: {
                        y: { beginAtZero: true, title: { display: true, text: 'Frequency' } }
                    },
                    plugins: {
                        legend: { display: false },
                        title: { display: true, text: 'Top 10 Token Frequency' }
                    }
                }
            });
        }
        
        // --- VIEW RENDERING / TAB SWITCHING ---

        function renderContent(tabId) {
            const contentElement = document.getElementById('main-content');
            let contentHTML = '';

            switch (tabId) {
                case 'data-ingestion':
                    contentHTML = `
                        <h2><i class="fas fa-database"></i> Data Ingestion</h2>
                        <p style="color: var(--secondary-text);">Upload a text file or paste text below to create the corpus for model training. A larger, higher-quality corpus will yield better results.</p>
                        
                        <!-- File Upload Card -->
                        <div class="card">
                            <h3><i class="fas fa-file-upload"></i> 1. Upload Text File (.txt)</h3>
                            <input type="file" id="corpus-file-upload" accept=".txt">
                        </div>

                        <!-- Paste Text Card -->
                        <div class="card">
                            <h3><i class="fas fa-paste"></i> 2. Paste Text Manually</h3>
                            <textarea id="manual-text-input" rows="8" placeholder="Paste your text corpus here..."></textarea>
                            <button class="button-primary" style="margin-top: 10px;" onclick="handleTextPaste()">Ingest Text</button>
                        </div>
                        
                        <!-- Stats Card -->
                        <div class="card">
                            <h3><i class="fas fa-chart-bar"></i> Corpus Statistics</h3>
                            <div id="ingestion-stats">
                                <p><strong>Status:</strong> No corpus loaded.</p>
                                <p><strong>Tokens:</strong> 0</p>
                                <p><strong>Vocabulary Size:</strong> 0</p>
                            </div>
                        </div>

                        <!-- Cloud Security Warning Section (UPDATED) -->
                        <div style="margin-top: 30px; padding: 15px; border: 1px solid #FFD7D7; background-color: #FFF2F2; border-radius: 6px;">
                            <h3 style="color: var(--google-red); margin-top: 0;"><i class="fas fa-lock"></i> Security Note: Cloud Streaming Limitations</h3>
                            <p style="color: var(--text-color); margin-bottom: 5px;">
                                For your security, this client-side application **cannot** support direct streaming of data from cloud services like **AWS S3** or **Google Cloud Storage (GCS)**. This is necessary to prevent credential leakage.
                            </p>
                            <ul style="margin-left: 20px; list-style-type: disc; color: var(--text-color);">
                                <li>**AWS Credentials:** Retrieving raw, potentially sensitive data from S3 requires providing **AWS keys**. Storing these keys in client-side JavaScript is a major security risk, as they can be easily inspected and stolen by any user.</li>
                                <li>**Pre-Signed URLs:** While a more secure AWS method, generating a **temporary, time-limited URL** for the client still requires a **secure backend server** to manage the signing process. Since this application is a single, static HTML file without a dedicated server, this crucial step cannot be implemented securely.</li>
                            </ul>
                            <p style="color: var(--text-color); margin-top: 15px;">
                                Please use the **File Upload** or **Paste Text** methods above to securely train your models with locally retrieved data.
                            </p>
                        </div>
                    `;
                    // Hook up event listener after rendering
                    setTimeout(() => {
                        document.getElementById('corpus-file-upload')?.addEventListener('change', handleFileUpload);
                        if (state.corpus) updateIngestionStats();
                    }, 0);
                    break;

                case 'model-training':
                    contentHTML = `
                        <h2><i class="fas fa-brain"></i> Model Training</h2>
                        <p style="color: var(--secondary-text);">Select a model type and adjust parameters, then start training on your ingested corpus.</p>

                        <!-- Training Settings Card -->
                        <div class="card" id="training-settings">
                            <h3><i class="fas fa-cogs"></i> Training Parameters</h3>
                            <label for="model-mode" style="display: block; margin-bottom: 10px; font-weight: 500;">Select Model Mode:</label>
                            <select id="model-mode" style="padding: 8px; border: 1px solid var(--border-color); border-radius: 4px; width: 100%; margin-bottom: 15px;">
                                <option value="MARKOV" ${state.mode === 'MARKOV' ? 'selected' : ''}>Markov Chain (Simple, Fast)</option>
                                <option value="TRANSFORMER" ${state.mode === 'TRANSFORMER' ? 'selected' : ''}>Mini-Transformer (Advanced, Slower)</option>
                            </select>

                            <div id="markov-settings" style="display: ${state.mode === 'MARKOV' ? 'block' : 'none'};">
                                <label for="markov-order" style="display: block; margin-bottom: 5px;">Markov Chain Order (N-gram size):</label>
                                <input type="number" id="markov-order" value="${CONFIG.markovOrder}" min="1" max="5" onchange="CONFIG.markovOrder=parseInt(this.value);" style="width: 100px;">
                                <p><small style="color: var(--secondary-text);">Higher order = more context, but needs more data.</small></p>
                            </div>
                            
                            <div id="transformer-settings" style="display: ${state.mode === 'TRANSFORMER' ? 'block' : 'none'};">
                                <label for="transformer-epochs" style="display: block; margin-bottom: 5px;">Epochs:</label>
                                <input type="number" id="transformer-epochs" value="${CONFIG.transformerEpochs}" min="1" max="100" onchange="CONFIG.transformerEpochs=parseInt(this.value);" style="width: 100px; margin-bottom: 10px;">
                                
                                <label for="transformer-size" style="display: block; margin-bottom: 5px;">Model Size (Embedding/Hidden Dim):</label>
                                <input type="number" id="transformer-size" value="${CONFIG.transformerModelSize}" min="32" max="256" step="32" onchange="CONFIG.transformerModelSize=parseInt(this.value);" style="width: 100px;">
                                <p><small style="color: var(--secondary-text);">Higher size/epochs = better model, but significantly slower.</small></p>
                            </div>

                            <button class="button-primary" id="train-model-button" style="margin-top: 20px;" onclick="startTraining()" ${state.corpus ? '' : 'disabled'}>
                                ${state.corpus ? 'Start Training' : 'Ingest Data First'}
                            </button>
                        </div>
                        
                        <!-- Training Status Card -->
                        <div class="card">
                            <h3><i class="fas fa-info-circle"></i> Training Status</h3>
                            <div id="current-model-info" style="margin-bottom: 15px;">
                                <p><strong>Corpus Status:</strong> ${state.corpus ? `<span style="color: var(--google-green);">Loaded (${state.vocabSize} words)</span>` : '<span style="color: var(--google-red);">Not Loaded</span>'}</p>
                            </div>
                            <div id="training-status">
                                <p>Awaiting training start...</p>
                            </div>
                            <div id="chart-container" style="margin-top: 20px;">
                                <canvas id="loss-chart"></canvas>
                            </div>
                        </div>
                    `;
                    
                    // Hook up event listener for mode change
                    setTimeout(() => {
                        const modeSelect = document.getElementById('model-mode');
                        const markovSettings = document.getElementById('markov-settings');
                        const transformerSettings = document.getElementById('transformer-settings');

                        modeSelect.addEventListener('change', (e) => {
                            if (e.target.value === 'MARKOV') {
                                markovSettings.style.display = 'block';
                                transformerSettings.style.display = 'none';
                            } else {
                                markovSettings.style.display = 'none';
                                transformerSettings.style.display = 'block';
                            }
                        });
                    }, 0);
                    break;

                case 'text-generation':
                    contentHTML = `
                        <h2><i class="fas fa-keyboard"></i> Text Generation</h2>
                        <p style="color: var(--secondary-text);">Enter a prompt and generate text using the currently trained model.</p>
                        
                        <!-- Generation Card -->
                        <div class="card">
                            <h3><i class="fas fa-pen-alt"></i> Generation Prompt</h3>
                            <div style="margin-bottom: 15px;">
                                <label for="generation-temp" style="display: block; margin-bottom: 5px;">Temperature (Creativity):</label>
                                <input type="number" id="generation-temp" value="${CONFIG.temperature}" min="0.1" max="2.0" step="0.1" onchange="CONFIG.temperature=parseFloat(this.value);" style="width: 100px;">
                                <p><small style="color: var(--secondary-text);">Lower = more focused/repetitive. Higher = more random/creative.</small></p>
                            </div>

                            <textarea id="generation-prompt" rows="4" placeholder="Start your prompt here (e.g., The best thing about AI is...)" style="margin-bottom: 10px;"></textarea>
                            <button class="button-primary" onclick="startGeneration()" ${state.mode ? '' : 'disabled'}>
                                Generate Text (${state.mode || 'No Model'})
                            </button>
                        </div>

                        <!-- Output Card -->
                        <div class="card">
                            <h3><i class="fas fa-comment-dots"></i> Generated Output</h3>
                            <div id="generation-output" style="min-height: 100px; padding: 10px; border: 1px solid var(--border-color); border-radius: 4px; background-color: var(--nav-panel-color);">
                                <em>Output will appear here after generation.</em>
                            </div>
                        </div>
                    `;
                    break;

                case 'analysis':
                    contentHTML = `
                        <h2><i class="fas fa-chart-line"></i> Corpus Analysis</h2>
                        <p style="color: var(--secondary-text);">Get statistics and visualizations for the currently ingested text corpus.</p>
                        
                        <div class="card">
                            <button class="button-primary" onclick="runAnalysis()" ${state.corpus ? '' : 'disabled'}>
                                Run Corpus Analysis
                            </button>
                            <p style="margin-top: 10px;"><small style="color: var(--secondary-text);">Analysis is only available after ingesting a corpus.</small></p>
                        </div>

                        <div id="analysis-summary" style="margin-bottom: 20px;">
                            <!-- Summary will be populated here -->
                            <div class="card">
                                <h3>Corpus Statistics</h3>
                                <p>Run analysis to see corpus details.</p>
                            </div>
                        </div>

                        <div class="card">
                            <h3>Token Frequency Visualization</h3>
                            <div id="analysis-output" style="min-height: 300px;">
                                <canvas id="analysis-chart"></canvas>
                            </div>
                        </div>
                    `;
                    setTimeout(() => {
                        if (state.corpus) runAnalysis();
                    }, 0);
                    break;
            }

            contentElement.innerHTML = contentHTML;
        }

        function setActiveTab(tabId) {
            // Update state
            state.activeTab = tabId;

            // Update navigation styles
            document.querySelectorAll('.nav-item').forEach(item => {
                item.classList.remove('active');
                if (item.getAttribute('data-tab-id') === tabId) {
                    item.classList.add('active');
                }
            });

            // Render new content
            renderContent(tabId);
        }

        // --- INITIALIZATION ---
        document.addEventListener('DOMContentLoaded', () => {
            // Set up navigation click listeners
            document.querySelectorAll('.nav-item').forEach(item => {
                item.addEventListener('click', () => {
                    setActiveTab(item.getAttribute('data-tab-id'));
                });
            });

            // Load initial content
            setActiveTab(state.activeTab);
        });
    </script>
</body>
</html>



